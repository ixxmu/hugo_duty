---
title: "对比 4 款 AI 阅读工具，我找到了「阅读文档」的最佳助手"
date: 2023-05-24T23:12:06Z
draft: ["false"]
tags: [
  "fetched",
  "少数派"
]
categories: ["Duty"]
---
对比 4 款 AI 阅读工具，我找到了「阅读文档」的最佳助手 by 少数派
------
<div><p><span>手动搜索和提炼信息时，我们常常遇到这些恼人的问题：</span></p><p><span>• </span><strong><span>信息太多</span></strong><span>，而人的阅读速度是有上限的；</span></p><p><span><span>• </span><strong>信息太杂</strong>，要对查找到的信息进行多次筛选和过滤；</span></p><p><span><span>• </span><strong>信息太晦涩，看不懂</strong>，而你需要一个通俗的新手村友好版本；</span></p><p><span><span>• </span><strong>信息涉及多个议题</strong>，要从线性的文章中梳理出树状的结构、网状的思维；</span></p><p><img data-galleryid="" data-ratio="0.4" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oylw20gGnRhKo8ldl5o2OX6tqq9QB50RrOo0cBBmuYnbkl48NdjiaHcvjXSMdSUWfRhm5tiaZuo7GDI8uWiaMaibFw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1000" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oylw20gGnRhKo8ldl5o2OX6tqq9QB50RrOo0cBBmuYnbkl48NdjiaHcvjXSMdSUWfRhm5tiaZuo7GDI8uWiaMaibFw/640?wx_fmt=jpeg"></p><p><span>获取信息的质量和速度，决定了我们决策的质量。如果能够「秒读」千百篇文献、指南、政策、规定、招股书、访谈纪要，快速得到大纲或精华内容就好了。最近 ChatDOC、ChatPDF、Humata 等 AI 文档阅读助手就赋予了我们这种能力：直接和单个或多个文档对话，在一问一答之间，化信息为洞察。</span></p><p><img data-ratio="0.5722222222222222" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIfsswiakFibzxl7GUvL2E2PCf8O9WicwtlzTH32aja544pnia5wn91AajPQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIfsswiakFibzxl7GUvL2E2PCf8O9WicwtlzTH32aja544pnia5wn91AajPQ/640?wx_fmt=png"></p><p><span>但是问题又来了，为什么有时候这类 AI 助手的回答表现很惊艳，有时候又差强人意？这跟 AI 工具本身的性能、技术原理有关，也跟我们的提问方式有关。本期文章将为你介绍：</span></p><p><span>1. AI 阅读工具测评；</span></p><p><span>2. 它们擅长的以及不擅长的；</span></p><p><span>3. 如何写出好的提示语（prompt）。</span></p><h2 hid="ss-hId-1"><span><strong>📱</strong></span></h2><h2 hid="ss-hId-1"><strong><span>AI 阅读工具测评</span></strong><br></h2><p><span>我尝试了 4 款 AI 阅读工具，先说结论：ChatDOC 从准确度和产品功能上显著优于其他几款，如果是严肃的工作/研究场合使用，ChatDOC 是首选。</span></p><p><img data-galleryid="" data-ratio="0.462037037037037" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIBgztR5SlcWee0DrFguPTvXlFmJ6icUlrwLThqy2flNMIVq9DnnNo0Og/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIBgztR5SlcWee0DrFguPTvXlFmJ6icUlrwLThqy2flNMIVq9DnnNo0Og/640?wx_fmt=png"></p><p><span><strong>▍</strong></span><strong><span>准确度</span></strong></p><p><span>准确度是首要指标。如果提取的信息有问题，反而会给信息处理工作带来更多麻烦。<strong>从数据的准确度上看，只有 ChatDOC 具有可用性</strong>。</span></p><p><span>为了测试准确度，我分别在四个软件上传了同一份学术论文，对其中的实验数据进行提问。</span></p><blockquote><p><span>What is the performance of BioBERT Fine-tuned on original data in dataset GAD?</span></p></blockquote><p><span>原 PDF 中的实验数据为 84.14、92.53 和 88.13。对应的参考示例如下：</span></p><p><img data-ratio="0.8935185185185185" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhISrWYgnk1bBMUh8DjkTZoEcxxyg15vWbTq5xia37WkVYk0gty8Gq5aiaw/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhISrWYgnk1bBMUh8DjkTZoEcxxyg15vWbTq5xia37WkVYk0gty8Gq5aiaw/640?wx_fmt=png"></p><p><span>ChatDOC 全部回答正确，并精准定位到了原文表格：</span></p><p><img data-ratio="0.21574074074074073" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIdECMt7EPTzKicJKmb945xFiaHwgqy1ic3xmHmBvwiaNEvqorQb6pq7cD2A/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIdECMt7EPTzKicJKmb945xFiaHwgqy1ic3xmHmBvwiaNEvqorQb6pq7cD2A/640?wx_fmt=png"></p><p><span>PandaGPT 找对了位置，但只给出了一个数据，数据还是错的：</span></p><p><img data-ratio="0.5410447761194029" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIv35tmDQMWNCaoYAyZSsk5rkv8zhOlTibORNLVlutaicQXqQBRxvIm1lQ/640?wx_fmt=png" data-type="png" data-w="1072" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIv35tmDQMWNCaoYAyZSsk5rkv8zhOlTibORNLVlutaicQXqQBRxvIm1lQ/640?wx_fmt=png"></p><p><span>ChatPDF 不支持原文溯源，虽然找到了三个数，但给到的三个数据全部是错的：</span></p><p><img data-ratio="0.2222222222222222" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhI4GXDdRVMeExBibCuhu9B5jcWmXwlz6n1vf1m5gcTjXGWzzBm0RC3ZlQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhI4GXDdRVMeExBibCuhu9B5jcWmXwlz6n1vf1m5gcTjXGWzzBm0RC3ZlQ/640?wx_fmt=png"></p><p><span>Humata 干脆摆烂了，告诉我原文中没有这个数。</span></p><p><img data-ratio="0.40555555555555556" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIu5ibc8NnXiaJOloPyicH5KtX5bhLg3BpIYJnIrCiaPiaaCPtaabnZXNz7Ww/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIu5ibc8NnXiaJOloPyicH5KtX5bhLg3BpIYJnIrCiaPiaaCPtaabnZXNz7Ww/640?wx_fmt=png"></p><h3><span><strong><strong>▍</strong>丰富度</strong></span></h3><p><span>另一个比较刚需的场景是提炼、概括重点内容，因此对于上述文档，我又测试了一个摘要性问题：</span></p><blockquote><p><span>总结一下这篇文章的主要内容。</span></p></blockquote><p><span>结论是<strong> ChatDOC、PandaGPT、Humata 的表现都不错，但 ChatPDF 给出的回答过于概括了</strong>。对应的参考示例如下：</span></p><p><span>ChatDOC：表现不错，给出了有信息量的摘要。</span></p><p><img data-ratio="0.6742424242424242" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhITJiacHm6Er7RQ2G1jRJFh3UZg6A572NP32IYlgk66CI1IHsY5Nk6Kjg/640?wx_fmt=png" data-type="png" data-w="1056" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhITJiacHm6Er7RQ2G1jRJFh3UZg6A572NP32IYlgk66CI1IHsY5Nk6Kjg/640?wx_fmt=png"></p><p><span>ChatPDF：过于简略，对于了解文章的帮助不大。</span></p><p><img data-ratio="0.2361111111111111" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIknARuvch4f7SY18jOnTc8Uiaf5159WBq0OKDGmyfBoicGNUQO3ziaYmicw/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIknARuvch4f7SY18jOnTc8Uiaf5159WBq0OKDGmyfBoicGNUQO3ziaYmicw/640?wx_fmt=png"></p><p><span>Humata：表现不错，给出了有信息量的摘要。</span></p><p><img data-ratio="0.5861111111111111" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIAJb2m6wRLGOatRia0ibthFSvp6uXnyfQooMuuRlCoGpo2ojK2tnrjTOg/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIAJb2m6wRLGOatRia0ibthFSvp6uXnyfQooMuuRlCoGpo2ojK2tnrjTOg/640?wx_fmt=png"></p><p><span>PandaGPT：表现不错，给出了有信息量的摘要。</span></p><p><img data-ratio="0.7518939393939394" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIwLKNTFiaNc9Fv2fqPOD2M7vS3EwRZGdQJmtk8VoQwehGzL53mMIddibw/640?wx_fmt=png" data-type="png" data-w="1056" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIwLKNTFiaNc9Fv2fqPOD2M7vS3EwRZGdQJmtk8VoQwehGzL53mMIddibw/640?wx_fmt=png"></p><h3><span><strong><strong>▍</strong>引用来源</strong></span></h3><p><span>许多 AI 问答</span><span>类的产品，包括 New Bing，为了规避大语言模型可能的胡说八道，都做了列出引用来源的设计。</span></p><p><span>ChatDOC 的引用做得很精细，回答中每一句话的末尾都给出了来源，且能一一对应；Humata、PandaGPT 的回答整体给出了引用页码，但颗粒度比较粗；而 ChatPDF 暂时没有这样的设计。对应的参考示例如下：</span></p><p><span>ChatDOC：每一个回答的每一句话都会给出来源，且精确到段落。</span></p><p><img data-ratio="0.5944444444444444" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhm9kVOmic89f7X0oAaNSCuSPBqbs2RGW8f9ymoPzNM4ZdEWL7siccEicQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhm9kVOmic89f7X0oAaNSCuSPBqbs2RGW8f9ymoPzNM4ZdEWL7siccEicQ/640?wx_fmt=png"></p><p><span>Humata、PandaGPT：对于包含数据的问答会给出来源，且精确到页；摘要、类比性质的问答，则不会给出来源。</span></p><p><span>ChatPDF：无。</span></p><h3><strong><span><strong>▍</strong>多文档提问</span></strong></h3><p><span>ChatDOC、Humata 支持上传一个文件夹，对文件夹进行整体提问；ChatDOC 目前免费用户即可使用，而 Humata 是付费功能；ChatPDF、PandaGPT 暂不支持。</span></p><p><span>对应的参考示例如下：</span></p><p><span>ChatDOC 在操作上需在本地将文件收集到一个文件夹里，再整体上传。而体验上，ChatDOC 的多文档概要比较准确；在引用来源的处理上，给出了具体文档名称和页码。</span></p><p><img data-ratio="0.5648148148148148" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhINzGZw68ZibiaLPqBCEhg9NZuKePeyHreA1k9Pevtajia2iciaIeOPeickHEw/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhINzGZw68ZibiaLPqBCEhg9NZuKePeyHreA1k9Pevtajia2iciaIeOPeickHEw/640?wx_fmt=png"></p><p><span>在<span>操作上，<span>Humata </span>免费版用户只能一个一个文件上传，付费用户支持多选文件上传。因为此功能</span></span><span>仅付费会员可使用，所以我没有继续尝试。</span></p><p><img data-ratio="0.8537414965986394" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhITLdI2H0GnG4tTUtO4tUiahG9Uicngulz1pe52oiaFpXicMOia0rZoN35Qwg/640?wx_fmt=png" data-type="png" data-w="588" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhITLdI2H0GnG4tTUtO4tUiahG9Uicngulz1pe52oiaFpXicMOia0rZoN35Qwg/640?wx_fmt=png"></p><h3><strong><span><strong>▍</strong>多轮追问</span></strong></h3><p><span>关于上下文记忆以及多轮追问，这几款产品提供了两种处理方式，分别是开启 Thread 进行追问或者直接在对话框里追问，默认记录上下文语境。</span></p><p><span>在 ChatDOC 中，你可以选择保留/不保留上下文。</span><span>ChatDOC 采用了类似于 Twitter上的「Thread」的概念：</span><span>你可以针对某一条回答点击多轮会话按钮，开启 Thread，这样的对话记录了关于这个问题的上下文。</span><span></span></p><p><img data-ratio="0.6242990654205608" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIjaJG27VapbrUf5f1ACTH8TtuU9KJZRM3JmL3Ub4BtWUDbolW0bm3Jw/640?wx_fmt=png" data-type="png" data-w="1070" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIjaJG27VapbrUf5f1ACTH8TtuU9KJZRM3JmL3Ub4BtWUDbolW0bm3Jw/640?wx_fmt=png"></p><p><span>在多轮追问中，你还可以设定 AI 的自主度，是更自由的 Go F</span><span>reely，还是严格按照文档回答。</span></p><p><img data-ratio="1.2045028142589118" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIt91z0srYAuM1g9yjxRylyAWx3eH1X1bia0lsgfZcqmemtwC9FuhS85A/640?wx_fmt=png" data-type="png" data-w="1066" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIt91z0srYAuM1g9yjxRylyAWx3eH1X1bia0lsgfZcqmemtwC9FuhS85A/640?wx_fmt=png"></p><p><span>在单轮问题的主聊天框里，默认是不记录上下文的，每个请求都是单独的问答对。</span></p><p><span>其他三款产品没有 Thread 的设计，但 ChatPDF、Humata 明显是做了上下文记忆的，可以直接继续追问；而 PandaGPT 似乎没有记忆上下文的能力，无法追问。</span></p><p><span>对应的参考示例如下：</span><span></span></p><p><img data-ratio="0.5703703703703704" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIQVNlge0KTdoFoC4rdTibCbO53zp2zb1H29L3LwEEVpDexibefOBhxZww/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIQVNlge0KTdoFoC4rdTibCbO53zp2zb1H29L3LwEEVpDexibefOBhxZww/640?wx_fmt=png"></p><p><span>ChatPDF</span><strong><span></span></strong><span></span></p><p><img data-ratio="0.6287037037037037" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhOkUl1Rotic4vDLwhJhrtfnecHH5PIbxNCdJWr0YJtbTJ5SES116ibiaQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhOkUl1Rotic4vDLwhJhrtfnecHH5PIbxNCdJWr0YJtbTJ5SES116ibiaQ/640?wx_fmt=png"></p><p><span>Humata</span></p><p><img data-ratio="0.9425287356321839" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhpAG5ibz4EetqEe0rOYovUoibIsyKTibJBK8vWryKQE4vlD4mgcib1mccw/640?wx_fmt=png" data-type="png" data-w="1044" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIhpAG5ibz4EetqEe0rOYovUoibIsyKTibJBK8vWryKQE4vlD4mgcib1mccw/640?wx_fmt=png"></p><p><span>PandaGPT</span></p><p><span>这里就是仁者见仁智者见智了。ChatDOC、ChatPDF、Humata 都可以进行追问。ChatDOC 是针对某一问答进行追问，在 Thread 里保留关于此议题的所有语境；而 ChatPDF、Humata 则是自动保持几个问答之间的上下文，操作起来更直观，但问题在于轮次多了之后会遗漏早先的语境。</span></p><h2 hid="ss-hId-2"><span><strong>🤖️</strong></span></h2><h2 hid="ss-hId-2"><strong><span>了解 AI 工具</span></strong></h2><p><strong><span>为什么几款工具会存在这样的差异？</span></strong><span>首先我们要理解「输入」和「输出」的概念。</span></p><p><span>所谓的「与文档对话」，在每一次对 ChatDOC 们的提问时，实际上是将我们的问题和文档内容作为「输入」，传给了大语言模型的接口，由它返回给我们「输出」，也就是我们在聊天中得到的解答。</span></p><p><span>目前由于大语言模型的 token 记忆限制（e.g. ChatGPT 的限制为 4096 个 token，约 3000 词；其他大语言模型目前的 token 限制一般在 2000-8000 之间），当我们提问时，ChatDOC 们无法将整篇文章的内容和我们的提问都输入进去，而是根据问题的语义，匹配相关度高的文章片段，传送给大语言模型的 API，得到最终答案。</span></p><p><span>也就是说，基于我们的提问，ChatDOC 们并非在整篇文章里进行检索，而是在最相关的片段里寻找答案。由此我们便可以总结一下 ChatDOC 的优缺点，做到趋利避害了。</span></p><h3><strong><span><strong>▍</strong>ChatDOC 们擅长的任务</span></strong></h3><p><span>ChatDOC 们擅长处理基于「重点内容」的相关任务，包括但不限于：</span></p><p><span>1. <strong>生成摘要，提炼重点</strong>。</span><span>根据近似度匹配，它们擅长理解你的需求，并据此提炼重点。</span><span>比如：</span></p><blockquote><p><span>介绍本论文的主要内容；</span></p><p><span>总结说话人 A 的主要观点；</span></p><p><span>介绍该公司的投资策略及业务侧重点有何转变；</span></p><p><span>进行周度/阅读的数据整理。</span></p></blockquote><p><span>2. <strong>阐释概念，解释步骤</strong>。大语言模型接受过世界知识的训练，能够提供良好的背景信息补充和专业解释。比如：</span></p><blockquote><p><span>「灾难性遗忘」是什么意思？</span></p><p><span>什么是大语言模型？</span></p><p><span>开一家淘宝店铺需要哪几个步骤？（你还可以通过多轮追问，让它阐释子步骤，从而在同一个主题下生成、组织和优化内容。）</span></p></blockquote><p><span>3. <strong>选中内容，智能分析</strong>。给到大语言模型的输入会完全囊括选中内容，因此 AI 能充分理解问题的上下文。比如：</span></p><blockquote><p><span>选中个股数据，并输入「请对该只股票近期的数据表现进行点评」。</span></p><p><span>选中实验数据结果，并输入「请总结该实验结果的数据结论」。</span></p></blockquote><p><span>4. <strong>用结构化的形式呈现信息</strong>。让它帮你整理关于某一话题的信息，以表格或者大纲的形式列出。这个步骤实际上是在进行语义匹配的搜索，将碎片化的信息围绕几个关键词凝结起来，并以结构化的形式呈现。</span></p><blockquote><p><span>分析一下基金投资策略的优缺点，打上标签，并以 markdown 表格的形式输出。</span></p><p><span>请依次告诉我这篇招股书的行业背景、核心技术、市场地位、公司历史沿革、主要财务指标、股东情况，用大纲列表的形式输出。</span></p></blockquote><h3><strong><span><strong>▍</strong>暂不擅长</span></strong></h3><p><span>而由于前文所述的记忆限制， ChatDOC 们暂不擅长精确的「全文定位」任务。</span><span>比如寻找某个数据在原文中的精确位置（⌘Command-F 更能帮你达到这一目的），或者</span><span>选中某条法规，让它列出这条法规在哪些文中的页数出现过。</span></p><section><span>✏️</span></section><h2 hid="ss-hId-3"><span><strong>Prompt 写作指南</strong></span></h2><section><span>在 ChatDOC 们擅长的任务中，我们也可以通过优化提示语（Prompt）获得更理想的答案。以下是几个亲测有效的方法：</span></section><h3><strong><span><strong>▍</strong>指示要明确</span></strong></h3><section><span>尽可能地减少解释空间，限制 AI 的操作范围。比如明确列出你希望 AI 帮你总结的字段，明确需要注意的细节，明确输出的格式。比如：</span></section><blockquote><section><span>请使用小红书流行的文案风格概括总结这篇文章。小红书的风格，特点是：</span></section><section><span>1. 引人入胜的标题；<br>2. 每个段落中包含表情符号；<br>3. 在末尾添加相关标签；</span></section><section><span>请确保原文的意思保持不变。</span></section></blockquote><h3><strong><span><strong>▍</strong>把任务分解</span></strong></h3><section><span>把一个大的问题拆解为细分步骤，每个逻辑步骤清晰，告诉 AI 第一步做什么，第二步接着做什么。比如：</span></section><blockquote><section><span>选中的表格数据，是 A 公司近期的股票数据。请你根据选中的数据完成以下两个任务：</span></section><section><span>1. 请对 A 公司近期的股票数据进行点评 。<br>2. 根据收盘价计算每日收益率，并以表格的形式输出。</span></section></blockquote><h3><strong><span><strong>▍</strong>定义角色</span></strong></h3><section><span>告诉 AI 它现在需要以一个什么样的身份来回答问题。比如：</span></section><blockquote><section><span>你现在是一名帮助我回答税收相关问题的助理。回答问题时，请遵循以下要求：</span></section><section><span>1. 只回答跟税收相关的问题。<br>2. 如果你不确定问题的答案，请回答「我不确定」。<br></span></section></blockquote><h3><strong><span><strong>▍</strong>明确输出的格式</span></strong></h3><section><span>你可以让 AI 输出表格、大纲。比如：</span></section><blockquote><section><span>请使用大纲列表 outliner 的形式，依次告诉我这篇文章的引言、文献回顾、理论框架、创新点、研究方法、研究过程、主要观点和结论、进一步研究方向。</span></section><section><span>生成的回答格式如下，以此类推。每个部分的回答，要细分为多个子内容。- 引言 - 此处为引言内容。- 子内容 - 子内容 - 文献回顾 - 此处为文献回顾内容 - 子内容 - 子内容。</span></section></blockquote><section><span>也可以让它输出评分、解释。比如：</span></section><blockquote><section><span>你是一名助手，旨在分析语音数据中的情绪。选中的内容是用户 A 的语音数据。评分范围为 1-10（10 为最高），请给出评分，并解释为什么给出这个评级。</span></section></blockquote><h3><strong><span><strong>▍</strong>把指令放到提示语开始</span></strong></h3><section><span>在最开始时，告诉 AI 你希望它执行的任务，然后再共享其他上下文信息或示例，可以帮助产生更高质量的输出。</span></section><h3><strong><span><strong>▍</strong>最后重复一遍指令</span></strong></h3><section><span>模型容易受到最新偏差的影响，在这种情况下，末尾 Prompt 信息可能比开头 Prompt 信息对输出的影响更大。因此，当提示语比较长的时候，在 Prompt 末尾重复指令，是值得一试的方法。</span></section><section><span>除此之外，还推荐大家去看看微软官方出品的 Prompt 教程。</span></section><section><span>原文链接：</span></section><section><span>https://sspai.com/post/79869?utm_source=wechat&amp;utm_medium=social</span></section><section><span>作者：史圣圆<br></span></section><section><span>责编：Clyde</span></section><section><strong><span><strong><span><strong>/</strong></span><strong> 更多热门文章 </strong><span><strong>/</strong></span></strong></span></strong></section><section><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247554620&amp;idx=1&amp;sn=f5bf022107038e7920d7a6dc5024d491&amp;chksm=fdb3e356cac46a403e272df6f946ef35656a4e57fa717c518044d6dcb6723b09fa5678049c72&amp;scene=21#wechat_redirect" textvalue="你已选中了添加链接的内容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span><img data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="198" data-ratio="0.352" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhINy92iaBBMpqG3uAcq6PbvV6t1PkpxDpB9iakxFLAv1BN1ZAMxWDsZndQ/640?wx_fmt=png" data-type="png" data-w="1000" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhINy92iaBBMpqG3uAcq6PbvV6t1PkpxDpB9iakxFLAv1BN1ZAMxWDsZndQ/640?wx_fmt=png"></span></a></section><section><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247554549&amp;idx=1&amp;sn=2e29b682ce2141dcb1a5474534fe748a&amp;chksm=fdb3e09fcac46989d0b32738529adbcd5b2194ce7728ff61f39ab63e2c889f80e61a05eda4f5&amp;scene=21#wechat_redirect" textvalue="你已选中了添加链接的内容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span><img data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="198" data-ratio="0.352" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIIIUoq8z9JyIJDPs2gFbAY1GYu7avWbibgiaTWiagicrdf0LP6MoFfXPgow/640?wx_fmt=png" data-type="png" data-w="1000" src="https://mmbiz.qpic.cn/sz_mmbiz_png/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIIIUoq8z9JyIJDPs2gFbAY1GYu7avWbibgiaTWiagicrdf0LP6MoFfXPgow/640?wx_fmt=png"></span></a></section><section><img data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="225" data-ratio="0.4722222222222222" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIxsYWjAVwPb7t0JDHUZsSwGhPo7RPLQOmZicnfzPEZJeRGiaW39ETKbiaw/640?wx_fmt=jpeg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oylw20gGnRhibib5xTCyicW6U4viaQcHcGhIxsYWjAVwPb7t0JDHUZsSwGhPo7RPLQOmZicnfzPEZJeRGiaW39ETKbiaw/640?wx_fmt=jpeg"></section><section><img data-ratio="0.16" data-src="https://mmbiz.qpic.cn/sz_mmbiz_gif/oylw20gGnRia5eQ4a4yV4Qpwj5xOiaaKKiclUP2GvCckKna5gukbFmkUQpoVjdekXiawhY0jiaZALA2nYCQwzP50kfg/640?wx_fmt=gif" data-type="gif" data-w="1000" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/oylw20gGnRia5eQ4a4yV4Qpwj5xOiaaKKiclUP2GvCckKna5gukbFmkUQpoVjdekXiawhY0jiaZALA2nYCQwzP50kfg/640?wx_fmt=gif"></section><section><br></section><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/KUNiI3Qw4fvzRJVeZaAd1w",target="_blank" rel="noopener noreferrer">原文链接</a>
