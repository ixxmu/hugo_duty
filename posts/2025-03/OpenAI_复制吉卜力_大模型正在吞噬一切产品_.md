---
title: "OpenAI 复制吉卜力，大模型正在吞噬一切产品？"
date: 2025-03-28T00:05:39Z
draft: ["false"]
tags: [
  "fetched",
  "晚点LatePost"
]
categories: ["Duty"]
---
OpenAI 复制吉卜力，大模型正在吞噬一切产品？ by 晚点LatePost
------
<div><section><section><section><img data-backh="92" data-backw="562" data-imgfileid="100040915" data-ratio="0.16296296296296298" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWBXMShoyI177ibF5yXDhw72ialvqtHicFpT7QgYa87lVxMbVCicv45jfK2w/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_jpg/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWBXMShoyI177ibF5yXDhw72ialvqtHicFpT7QgYa87lVxMbVCicv45jfK2w/640?wx_fmt=jpeg&amp;from=appmsg"></section></section><section><section><img data-backh="449" data-backw="562" data-imgfileid="100040916" data-ratio="0.799074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWeibRLNx1OH3UQ2UniaAlpKYFEgFeBy9hDUTc9NvoMkxdttfYNrcCiaTibg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWeibRLNx1OH3UQ2UniaAlpKYFEgFeBy9hDUTc9NvoMkxdttfYNrcCiaTibg/640?wx_fmt=png&amp;from=appmsg"></section></section><section><section><section><p>题图由 GPT-4o 生成，提示词是“请你根据下面这句话生成一个吉卜力风格的图像：周围有一圈人，看着一个机器吐出图像”。</p></section></section></section><section><section><p><strong><br></strong></p><p><strong>文<span>丨</span>贺乾明</strong></p><p><strong>编辑<span>丨</span>黄俊杰</strong></p><p><strong><br></strong></p></section></section><section><section><p><span>新产品发布两天后，在 OpenAI 创始人山姆·阿尔特曼（Sam Altman）的推文下，有人祝贺他十年努力终于带来了 AGI——社交网络上全是吉卜力图像 “All Ghibli Images”。</span></p><p><br></p><p>3 月 26 日，OpenAI 更新 GPT-4o 文生图功能。付费用户可以在 ChatGPT 直接调用 4o 生成、修改图片，不再需要使用 OpenAI 的文生图模型 DALL-E。仅仅一天时间，近年影响较大的照片和 meme 图都被 4o 重做了一遍，最流行的就是宫崎骏的画风。</p></section></section><section><section><section><section><section><section><img data-imgfileid="100040917" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWVZ2zGxxNtHvyOqiclq7m8ZMrB8gSFdKYARjhKJniaVxL4tianWXW3Bfqg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWVZ2zGxxNtHvyOqiclq7m8ZMrB8gSFdKYARjhKJniaVxL4tianWXW3Bfqg/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040919" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWu80GLNF6T7dOmHia3PUV9zusCWOsqsFLYTfpfUiafW1pJyLo6gS4HAgg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWu80GLNF6T7dOmHia3PUV9zusCWOsqsFLYTfpfUiafW1pJyLo6gS4HAgg/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040918" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWbrdcW9zkmPmPOJdzRaczZ6DYxvLPNq5PS0FKxAuOYzhl71lkaj4DmA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWbrdcW9zkmPmPOJdzRaczZ6DYxvLPNq5PS0FKxAuOYzhl71lkaj4DmA/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040922" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWiaiaIibyH6ewOUbY7Y1hIett7ibDjVQBMMH1YaMwz4RGUicvEzPohQTPdSw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWiaiaIibyH6ewOUbY7Y1hIett7ibDjVQBMMH1YaMwz4RGUicvEzPohQTPdSw/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040921" data-ratio="0.6666666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWOjwN2ZOlc6LRTdHuPhibqCkMibfKNcWjy8dGgG3088SFWXn2RMPXWVSw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWOjwN2ZOlc6LRTdHuPhibqCkMibfKNcWjy8dGgG3088SFWXn2RMPXWVSw/640?wx_fmt=png&amp;from=appmsg"></section></section></section></section></section></section><section><section><section><section><section><p><br></p></section></section></section><section><section><p>左右滑动查看</p></section></section></section></section><section><section><p><span>人人都用生成吉卜力画风不仅仅因为宫崎骏对世界的卓绝贡献，也因为 OpenAI 的引导——阿尔特曼在 GPT-4o 新功能发布的直播里选择生成吉卜力风格的三人自拍照。但其实 GPT-4o 生成其他风格效果通常也不错。</span></p><p><br></p><p>文生图已经不新鲜，此前也有文生图产品能实现风格化效果。比如 Midjourney 年付费用户可以改照片风格，Stable Diffusion 也有专门训练成吉卜力风格的模型，Gemini 2.0 半个月前也增强了文生图功能。</p><p><br></p><p>但 GPT-4o 在多个领域明显超过所有对手，比如图像中的文字（尤其是英文）基本不再是乱码。以图生图时，画面细节更符合现实情况，修改图片时画面细节能保证较高的一致性。<span></span></p><section><section><section><section><section><section><section><img data-imgfileid="100040935" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWnpu6LxUEx16HSUeQ1M9qxlN6hmJFypMgkKk0nJlfsb5h5nPVVdMztg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1024" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWnpu6LxUEx16HSUeQ1M9qxlN6hmJFypMgkKk0nJlfsb5h5nPVVdMztg/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040936" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWFR0zkWibSQASr5f84SAE27sDwhXwI06yQaF3sEdZiaEEnrDlTQVLAtDA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWFR0zkWibSQASr5f84SAE27sDwhXwI06yQaF3sEdZiaEEnrDlTQVLAtDA/640?wx_fmt=png&amp;from=appmsg"></section></section></section></section></section></section></section></section></section><section><section><section><section><section><p><br></p></section></section></section><section><section><p>右图是原图，有两轮提示词，分别是 “保留图片中的文字，把图片改成动漫风格”“在周围加一圈猫”。（左右滑动查看）</p></section></section></section></section><section><section><section><section><section><section><img data-imgfileid="100040920" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYW9jBq0XEu1iaaufSTniciaVGKuCmFf7GmaYFyrgFz11CVUEbBdTiaWhDeFQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1024" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYW9jBq0XEu1iaaufSTniciaVGKuCmFf7GmaYFyrgFz11CVUEbBdTiaWhDeFQ/640?wx_fmt=png&amp;from=appmsg"></section></section></section><section><section><section><img data-imgfileid="100040929" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWFNcqtlf0QpEUoQut7AbI1wZ7zVmnia4sdNw4dXNiaE3qnKENwFUKc6VA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1024" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWFNcqtlf0QpEUoQut7AbI1wZ7zVmnia4sdNw4dXNiaE3qnKENwFUKc6VA/640?wx_fmt=png&amp;from=appmsg"></section></section></section></section></section></section><section><section><section><section><section><p><br></p></section></section></section><section><section><p>提示词是 “请帮我生成一个泡泡玛特的 MOLLY ，画面中是它正在爆炸起飞，像皇帝一样登基了，周围有人朝拜它”“那你改成 3D 版本”。（左右滑动查看）</p></section></section></section></section><section><section><p><span>GPT-4o 对技术普及影响最大的可能是控制更容易也更精确，整个过程不再需要复杂、精确的提示词，像平时说话一样给修改建议就行。</span></p><p><br></p><p>文生图开源模型 Stable Diffusion 在 2022 年发布。需要制图、画插画的行业很快就将它引入工作。但 Stable Diffusion 本身不够可控，于是 LoRA、ControlNet 等技术被发明出来，新的创业公司应运而生，帮助完善产品、提供服务，搭建起一套实际可用的工作流程。</p><p><br></p><p>“（GPT-4o）直接干翻了之前很多创业公司的产品。” 资深用户体验设计师章萧醇说。“他们花了那么多时间、人力、投资人的钱，调优的算法、工作流、模型，直接被一次大模型的更新取代了。”</p><p><br></p><p>“因为大模型变得过于强大，一种新型编程方式正在兴起。”AI 科学家安德烈·卡帕斯（Andrej Karpathy）把它称为 “Vibe Coding（氛围编程）”，“只是看东西、说话、运行程序和复制粘贴，就能开发程序，这套流程大多数时候都能正常工作。”</p><p><br></p><p>而 GPT-4o 的文生图功能就像是 Vibe Painting。</p></section></section><section><section><section><section><p><strong>技术细节有限，推论是 OpenAI 靠底层能力提升</strong></p></section></section></section></section><section><section><p>不论是 Google 还是 OpenAI，发布新的文生图功能时，都没有介绍技术细节，以至于许多人去问 ChatGPT，OpenAI 到底是怎么做到的。</p><p><br></p><p>相对权威的技术介绍，是 OpenAI 的研究员加布里埃尔·吴（Gabriel Goh）在直播中提到的两点：</p><p><br></p></section></section><section><section><section><section><section><section><p><br></p></section></section></section></section><section><section><section><p>全模态的 GPT-4o 是这项功能的基础，它有生成各种类型数据如文本、图像、音频和视频的能力。</p></section></section></section></section></section><section><section><section><section><section><section><p><br></p></section></section></section></section><section><section><section><p>采用自回归（autoregressive）方法（根据已经生成的内容来预测下一个元素）——从左到右、从上到下顺序生成图像，类似于文本的书写方式——而不是大多数图像生成模型（如 DALL-E）使用的扩散模型（Diffusion Model）技术，一次性创建整个图像，然后降噪提高清晰度。</p></section></section></section></section></section><section><section><p><br></p><p>GPT-4o 是 OpenAI 去年 5 月发布的大模型，与 GPT-4.5、DeepSeek-V3 等专注文本能力的模型不同，它用文本、视觉、音频等数据训练。OpenAI 称，它可以处理用户输入文本、音频、图像或视频的组合内容，也可以反馈文本、音频、图像或视频组合内容——不过现在 GPT-4o 还没有完全具备上述能力。</p><p><br></p><p>OpenAI 新发布的文生图功能，是其沿着 GPT-4o 技术路线发掘到的新成果。</p><p><br></p><p>清华大学 NICS-EFC 实验室专注文生图研究的博士生赵天辰对《晚点 LatePost》说，GPT-4o 用自回归技术可能不是图像生成能力大幅提升的核心原因，而是 OpenAI 大幅提升了“文本-图像对齐”（text-image alignment）能力。</p><p><br></p><p>行业内惯用的文生图模型，如 Midjourney、DALL-E 系列，生成图像时会用到多个组件：先理解用户输入的提示词，转换为文本特征，再聚合对应的图像特征，最后生成图像。</p><p><br></p><p>赵天辰说，目前开源的文生图模型，引入文本控制信号上，存在以下不足：</p><p><br></p></section></section><section><section><section><section><section><section><p><br></p></section></section></section></section><section><section><section><p>一般都采用较小的模型提取文本特征（CLIP/T5），文本的理解能力会受到 “不够强” 的文本制约，损失一些文本信息。</p></section></section></section></section></section><section><section><section><section><section><section><p><br></p></section></section></section></section><section><section><section><p>引入控制信号的方式 “相对朴素”，用注意力机制融合文本特征与图像特征，即使文本特征足够好，也无法保证图像特征能够准确遵循文本特征。</p></section></section></section></section></section><section><section><p><br></p><p>许多开发文生图工具的公司或者使用文生图工具的设计师，往往用精心调教的提示词、层层叠加的插件、环环相扣的模型链弥补缺陷，把它变成可用的工具。</p><p><br></p><p>OpenAI 用 GPT-4o 提升了模型的理解文本特征和提示词的能力。“如果我去画一幅图，虽然能力有限，但也会用自己积累的知识完成它”。ChatGPT 多模态产品负责人杰基·香农（Jackie Shannon）说，“大模型有通用知识，当你用 GPT-4o 生成一张牛顿棱镜实验的图像时，你不需要解释那是什么，就能得到相应的结果。”</p><p><br></p><p>赵天辰推测，OpenAI 模型展示出的惊艳文本遵从能力，尤其是能准确把握文本描述中多个对象，以及形容词和位置关系，可能很难通过传统的单次文生图“端到端”达成。在现有模型中，如果提示词中有很多颜色，比如 “蓝色的帽子” 和 “红色的衣服”，直接交给模型端到端生成，结果可能是衣服和帽子都有蓝有红，颜色混在一起。</p><p><br></p><p>GPT-4o 基本不会有类似错误。他认为可能采用了 “组合-分解式” 的生成方案，比如生成一个人在左边，再生成一条狗在右边，然后把这些图叠起来，最后整体生成一遍，把它们融合在一起。</p></section></section><section><section><section><section><p><strong>从编程到图片生成，大模型试图吞噬依赖它的应用</strong></p></section></section></section></section><section><section><p>编程是大模型最早规模商业化的场景。2021 年 OpenAI 推出 GPT-3 不久，微软就用它做出了 GitHub Copilot。</p><p><br></p><p>就像它的名字那样，受限于模型能力，GitHub Copilot 很长时间只能作为辅助编程工具，它最好用的场景是补全代码和 Debug，程序员还要做不少引导工作。</p><p><br></p><p>随着大模型能力持续提升，GitHub Copilot 在 2023 年用上新模型后，年化收入迅速突破 1 亿美元。行业内也诞生了 Cursor、甚至 Devin 这样的产品。它们集成了 Anthropic、OpenAI 的最新模型，编写简单的代码多数情况都不需要程序员干预，但写复杂的代码还是需要程序员引导。</p><p><br></p><p>Cursor 等产品还面临一批竞争对手——它们依赖的大模型公司，如 Anthropic、OpenAI 等。它们在持续提高大模型本身的编程能力，每一次更新都有可能削减 Cursor 等产品的价值。比如编程竞赛 CodeForces 的测试，OpenAI 的 o3 的编程能力已经达到了 Top 200 人类程序员的水平。虽然它并不代表实际的编程水平，但证明了大模型本身的潜力。</p><p><br></p><p>这就是安德烈·卡帕斯提出 Vibe Coding 的背景，编程 “几乎不用碰键盘”，收到报错信息时，只用复制粘贴进去，通常就能解决问题。</p><p><br></p><p>硅谷创业孵化器 YC  CEO 陈嘉兴（Garry Tan）接受采访说，创业者不再需要第一个 50 或 100 人的工程师团队，可以用 10 个人建立每年赚 1000 万或 1 亿美元的公司。最新一期 YC 创业营中，有 1/4 的公司采用 Vibe Coding， 95% 的代码由大模型直接生成。</p><p><br></p><p>GPT-4o 也推动文生图沿着类似的趋势发展。过去的文生图模型可以生产出来以假乱真的图像，但还是有足够高的门槛——更懂模型的人、更有审美的人、更会写提示词的人，再自己训练模型、找插件，可能还得动手 PS 一下，才能得到理想的图。</p><p><br></p><p>现在模型本身变成了一个聪明的专业人士。</p><p><br></p><p>“我曾引以为傲的复杂工作流程——精心调教的提示词、层层叠加的插件、环环相扣的模型链——如今都被一个简单对话界面所取代。” 资深产品设计师歸藏说，他认为这会是 AI 领域的常态，“复杂工程化注定会被模型碾碎”。</p><p><br></p><p>GPT-4o 图片生成功能推出后，文生图领域明星创业公司 Midjourney CEO 创始人大卫·霍尔兹（David Holz）在公司举办的活动中说，OpenAI 只是 “在试图筹钱，并以一种有毒的方式竞争，它只是一个梗而不是创意工具”，未来 Midjourney 还是会基于社区的反馈驱动改进，而不是外部的市场压力。</p><p><br></p><p>Midjourney 的成长得益于 OpenAI 在 2021 年推出的文本-图像对齐模型 CLIP。在后续的产品迭代中，Midjourney 用更精细的工程能力，对生成图像审美的苛刻关注，训练了效果更好的模型，仅靠 Discord  就迅速获得每年数亿美元的收入。类似的例子还有 AI 搜索应用 Perplexity。</p><p><br></p><p>如果大模型本身的能力进步有限，就是这类创业公司的机会——他们针对垂直领域的功能优化或者训练小模型，可以更好地发挥大模型效果。</p><p><br></p><p>但如果大模型能持续进步，许多精心调教后的产品能力成为庞大模型的一部分，用户直接说几句话就能实现想要的效果，那大模型本身就是终极产品。能投入组建大团队、巨资训练模型的公司才有资格参与大模型性能的比拼。</p><p><br></p><p>技术演进偏向哪一端，最终将决定 AI 生态的未来更偏向大公司还是新锐团队。</p></section></section><section><section><p><span><strong>-</strong></span><span><strong> FIN <span>-</span></strong></span><br></p></section></section><section><section><img data-backh="137" data-backw="562" data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="137" data-imgfileid="100040926" data-ratio="0.24444444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWPfS0FrLGnxsRUribdA5UYuWicFnVncaez8jCsOtib1Dib8gAds0o8mR1Kw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWPfS0FrLGnxsRUribdA5UYuWicFnVncaez8jCsOtib1Dib8gAds0o8mR1Kw/640?wx_fmt=png&amp;from=appmsg"></section></section><section><section><img data-backh="43" data-backw="112" data-imgfileid="100040927" data-ratio="0.3793103448275862" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYW30XZKLW4dBiarickf2KMnWO392Q1VtOFRn649vxJz1LpJKzYYiaEuFDoA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="319" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYW30XZKLW4dBiarickf2KMnWO392Q1VtOFRn649vxJz1LpJKzYYiaEuFDoA/640?wx_fmt=png&amp;from=appmsg"></section></section><section><section><a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzU3Mjk1OTQ0Ng==&amp;mid=2247524352&amp;idx=1&amp;sn=cb897bfabd3bae9f051c6b61fc42c932&amp;scene=21#wechat_redirect" textvalue="你已选中了添加链接的内容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span><img data-backh="275" data-backw="562" data-imgfileid="100040928" data-ratio="0.4888888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWM1rVl8ztNlicYQsFfTNtDulOPetJGxERKx1sR3Qh5CY2AZ34jvAJBSQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWM1rVl8ztNlicYQsFfTNtDulOPetJGxERKx1sR3Qh5CY2AZ34jvAJBSQ/640?wx_fmt=png&amp;from=appmsg"></span></a></section></section><section><section><img data-backh="162" data-backw="562" data-imgfileid="100040925" data-ratio="0.28888888888888886" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWeGr96VHPWBEVD1FDDjxJPLZKqWDbw0Xrz7x7PrwTLQDrMMNnwxFlnQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/VWpZENjIo5sM9R5rvwNjd5uGicXJaibWYWeGr96VHPWBEVD1FDDjxJPLZKqWDbw0Xrz7x7PrwTLQDrMMNnwxFlnQ/640?wx_fmt=png&amp;from=appmsg"></section></section></section><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/kk4URTXLVKQib_u_cty-6A",target="_blank" rel="noopener noreferrer">原文链接</a>
