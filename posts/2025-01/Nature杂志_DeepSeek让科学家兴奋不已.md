---
title: "Nature杂志：DeepSeek让科学家兴奋不已"
date: 2025-01-31T15:22:24Z
draft: ["false"]
tags: [
  "fetched",
  "cnbeta"
]
categories: ["Duty"]
---
Nature杂志：DeepSeek让科学家兴奋不已 by cnbeta
------
<div style="margin-top:10px" class="content" id="artibody"><p>1月31日消息，Nature自然杂志发表文章称，中国研制的大型语言模型DeepSeek-R1令科学家们兴奋不已，它被认为是 OpenAI 的o1等推理模型的经济实惠且开放的竞争对手。这些模型一步一步地生成响应，其过程类似于人类的推理。这使得它们比早期的语言模型更善于解决科学问题，也意味着它们可能在研究中有用。</p><div class="article-global"></div><p>1 月 20 日发布的 R1 的初步测试表明，它在化学、数学和编码的某些任务上的表现与 o1 相当——后者在 9 月由 OpenAI 发布时让研究人员惊叹不已。</p><p>“这太疯狂了，完全出乎意料。”人工智能研究员、英国人工智能咨询公司 DAIR.AI 联合创始人埃尔维斯·萨拉维亚 (Elvis Saravia) 在 X 上写道。</p><p>R1 脱颖而出还有另一个原因。建立该模型的杭州初创公司 DeepSeek 已将其作为开放模型发布，这意味着研究人员可以研究和构建该算法。该模型根据麻省理工学院的许可证发布，可以自由重复使用，但不被视为完全开源，因为其训练数据尚未公开。</p><p>德国埃尔朗根马克斯普朗克光科学研究所人工智能科学家实验室负责人马里奥·克伦 (Mario Krenn) 表示：DeepSeek 的开放性非常了不起。</p><p>相比之下，加州旧金山 OpenAI 建立的 o1 和其他模型（包括其最新成果 o3）本质上都是黑匣子，他说。</p><p>DeepSeek 尚未公布训练 R1 的全部成本，但其界面收费仅为 o1 运行成本的三十分之一。该公司还创建了 R1 的迷你精简版本，以允许计算能力有限的研究人员使用该模型。</p><p>“使用 o1 进行的实验成本超过 300 英镑 [370 美元]，而使用 R1 的成本不到 10 美元。”Krenn 说。“这是一个巨大的差异，肯定会对其未来的采用产生影响。”</p><p><strong>挑战模型</strong></p><p>R1 是中文大型语言模型 (LLM) 热潮的一部分。DeepSeek 从一家对冲基金中分拆出来，上个月发布了一款名为 V3 的聊天机器人，一举成名。尽管预算极低，但这款机器人的表现却超越了主要竞争对手。专家估计，租用训练该模型所需的硬件成本约为 600 万美元，而 Meta 的 Llama 3.1 405B 则高达 6000 万美元，使用的计算资源是 V3 的 11 倍。</p><p>DeepSeek 的部分热门话题是，尽管美国出口管制限制中国公司获得为人工智能处理而设计的最佳计算机芯片，但它还是成功制造了 R1。华盛顿西雅图的人工智能研究员 François Chollet 说：R1 来自中国，这一事实表明，高效利用资源比单纯的计算规模更重要。</p><p>DeepSeek 的进展表明美国曾经的领先优势已经大幅缩小，华盛顿州贝尔维尤的技术专家 Alvin Wang Graylin 在 X 上写道，他在HTC 工作。“中美两国需要采取合作的方式来打造先进的人工智能，而不是继续目前这种没有胜算的军备竞赛方式。”</p><p><strong>思路</strong></p><p>LLM 训练数十亿个文本样本，将它们剪切成单词部分（称为标记），并学习数据中的模式。这些关联允许模型预测句子中的后续标记。但 LLM 容易捏造事实，这种现象称为幻觉，并且经常难以推理问题。</p><p>与 o1 一样，R1 使用思路链方法来提高 LLM 解决更复杂任务的能力，包括有时回溯和评估其方法。DeepSeek 通过使用强化学习对 V3 进行微调来制作 R1，强化学习会奖励模型得出正确答案并以概述其思维的方式解决问题。</p><p><img src="https://static.cnbetacdn.com/article/2025/0131/8edff23414e798c.jpg" title="" alt="d41586-025-00229-6_50571546.jpg"></p><p>英国爱丁堡大学人工智能研究员 Wenda Li 表示，计算能力有限促使该公司在算法上进行创新。在强化学习过程中，该团队估算了模型在每个阶段的进度，而不是使用单独的网络对其进行评估。</p><p>英国剑桥大学计算机科学家 Mateja Jamnik 表示，这有助于降低培训和运行成本。研究人员还使用了混合专家架构，该架构允许模型仅激活与每项任务相关的部分。</p><p>在基准测试中， DeepSeek-R1 在加州大学伯克利分校研究人员编写的数学问题 MATH-500 中取得了 97.3% 的成绩，并在一项名为 Codeforces 的编程竞赛中击败了 96.3% 的人类参与者。这些能力与 o1 不相上下；o3 未被纳入比较范围（参见“AI 竞争对手”）。</p><p>很难判断基准测试是否反映了模型真正的推理或概括能力，还是仅仅反映了其通过此类测试的能力。但剑桥大学计算机科学家 Marco Dos Santos 表示，由于 R1 是开放的，研究人员可以访问其思路。“这使得模型的推理过程具有更好的可解释性。”他说。</p><p>科学家们已经开始测试 R1 的能力。克伦要求两个竞争模型对 3，000 个研究想法进行有趣程度排序，并将结果与人工排名进行比较。根据这一衡量标准，R1 的表现略逊于 o1。但克伦表示，R1 在量子光学的某些计算上胜过 o1。“这相当令人印象深刻。”</p></div>  
<hr>
<a href="https://m.cnbeta.com.tw/wap/view/1475042.htm",target="_blank" rel="noopener noreferrer">原文链接</a>
