---
title: "DeepSeek将与华为寒武纪合作发布V4多模态大模型"
date: 2026-03-01T00:37:36Z
draft: ["false"]
tags: [
  "fetched",
  "cnbeta"
]
categories: ["Duty"]
---
DeepSeek将与华为寒武纪合作发布V4多模态大模型 by cnbeta
------
<div style="margin-top:10px" class="content" id="artibody"><p>知情人士透露，中国人工智能公司 DeepSeek 计划于下周发布最新一代大语言模型 V4，这是该公司自上一款重磅产品推出一年多以来的首次重大更新，被视为中国在人工智能领域继续向美国竞争对手发起挑战的重要一步。</p><div class="article-global"></div><p><a href="https://static.cnbetacdn.com/article/2026/0214/eced5cde330da87.jpg" target="_blank"><img src="https://static.cnbetacdn.com/article/2026/0214/eced5cde330da87.jpg"></a></p><p>据两名了解内情的人士透露，DeepSeek 总部位于杭州，此次推出的 V4 将是一款具备图像、视频与文本生成能力的多模态模型。 多名知情人士称，DeepSeek 已与中国本土 AI 芯片厂商华为和寒武纪展开合作，对 V4 进行定制优化，以适配双方最新一代芯片产品，从而在算力层面形成更紧密的协同。 这一动作被视为中国科技企业加速摆脱对英伟达高端 AI 芯片依赖的又一信号，而这些芯片目前正受到美国出口管制限制，相关措施旨在遏制中国的技术崛起。</p><p>此次发布的时间点也颇具象征意义。DeepSeek 计划在中国一年一度的全国“两会”召开前夕推出 V4，而今年“两会”将于 3 月 4 日开幕。 这一高规格政治会议为该公司提供了重要的曝光窗口，或将进一步巩固其“国家级 AI 冠军”形象。</p><p>这是 DeepSeek 自 2025 年 1 月发布 R1 推理模型以来的首次大版本迭代。 当时公司宣称，仅凭远低于硅谷头部公司使用的算力规模，就训练出在能力上可比肩领先模型的系统。 这一消息一度在美国科技股市场引发震动，有分析人士将其形容为标志中国在人工智能领域快速追赶、甚至改写格局的“斯普特尼克时刻”。 自那以后，DeepSeek 更多推出的是渐进式更新，而非完整新架构，这也让包括阿里巴巴、月之暗面（Moonshot）在内的国内竞争对手在低成本、开源中文模型市场上获得了额外的成长空间。</p><p>多名知情人士预计，DeepSeek 此次专门针对国产 AI 芯片优化 V4，将有助于提振本土芯片的市场需求，并加速在模型推理阶段（即利用已训练模型生成回答的过程）向华为、寒武纪等中国厂商转移，降低对英伟达和 AMD 芯片的依赖。 路透社此前曾率先报道 DeepSeek 与华为、寒武纪的合作进展。 另一名了解情况的人士则表示，DeepSeek 并未与英伟达就 V4 的优化进行合作。</p><p>不过，在模型训练领域，英伟达仍占据主导地位，尤其是在需要巨量算力支持的预训练阶段，其 GPU 仍是行业标准。 《金融时报》此前报道称，DeepSeek 曾尝试在华为硬件上完成这一初始训练，但过程中遇到技术难题。 该公司去年在发布 R1 模型时，同时公开了一份详尽的技术报告，阐述如何在英伟达芯片上更高效地训练和运行模型，相关工程方法受到广泛关注与赞誉。 有业内人士认为，DeepSeek 分享其构建“推理模型”的训练方法，实际上为其他实验室提供了可复用的工程路径，帮助后者在有限算力条件下提升模型推理能力。</p><p>所谓“推理模型”，是指专门针对复杂问题求解进行优化的模型范式，其核心思路是将难题拆分为多个可逐步求解的子问题，再通过多步推理得出最终结论。 有接近 DeepSeek 计划的人士透露，公司预计将在下周发布 V4 的同时附上一份篇幅较短的技术说明文档，重点介绍关键改进点，并在大约一个月后推出更为详尽的技术报告，以系统性披露模型架构和训练方法。</p><p>与此同时，围绕知识产权与模型“借训”的争议也在升温。就在本周早些时候，美国 AI 公司 Anthropic 指控 DeepSeek 及另外两家中国 AI 实验室对其模型实施所谓“蒸馏攻击”，即利用更强大模型的输出对小型模型进行训练，使后者在不直接使用同等级算力资源的情况下接近前者性能。 对此，华为、DeepSeek 和寒武纪均未对置评请求作出回应。</p></div>  
<hr>
<a href="https://m.cnbeta.com.tw/wap/view/1551644.htm",target="_blank" rel="noopener noreferrer">原文链接</a>
