---
title: "刚刚！梁文锋亲自贡献：DeepSeek全面开源优化并行策略！"
date: 2025-02-27T04:33:11Z
draft: ["false"]
tags: [
  "fetched",
  "Datawhale"
]
categories: ["Duty"]
---
刚刚！梁文锋亲自贡献：DeepSeek全面开源优化并行策略！ by Datawhale
------
<div><section data-mpa-powered-by="yiban.io" data-style="-webkit-tap-highlight-color: transparent; margin-bottom: 0px; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; text-wrap: wrap; caret-color: rgb(34, 34, 34); font-family: 'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif; visibility: visible; line-height: 27.2px; color: rgb(163, 163, 163) !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453"><section data-mpa-powered-by="yiban.io" data-style="-webkit-tap-highlight-color: transparent; margin-bottom: 0px; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; text-wrap: wrap; caret-color: rgb(34, 34, 34); font-family: 'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif; visibility: visible; line-height: 27.2px; color: rgb(163, 163, 163) !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453"><section data-mpa-powered-by="yiban.io" data-style="-webkit-tap-highlight-color: transparent; margin-bottom: 0px; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; text-wrap: wrap; caret-color: rgb(34, 34, 34); font-family: 'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif; visibility: visible; line-height: 27.2px; color: rgb(163, 163, 163) !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453"><section data-mpa-powered-by="yiban.io"><section powered-by="xiumi.us"><section powered-by="xiumi.us"><section><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)"><section><p><span> Datawhale分享 </span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);"><p><span><strong>开源周：Day 04，编辑：Datawhale</strong><strong></strong></span></p></section></section></section></section><section><mp-common-profile data-id="MzIyNjM2MzQyNg==" data-pluginname="mpprofile" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsEXsBwQkpYLtE2vhn7Z3RVOSRu5M1VicIgqgMRKLsxsibK7OUSqUb1rUO4pfXnQyFYKqhryAIeh4MOg/300?wx_fmt=png&amp;wxfrom=19" data-nickname="Datawhale" data-alias="Datawhale" data-signature="一个专注于AI领域的开源组织，汇聚了众多优秀学习者，使命-for the learner，和学习者一起成长。" data-from="2" data-is_biz_ban="0" data-weui-theme="light" data-origin_num="719" data-isban="0" data-biz_account_status="0" data-index="0"></mp-common-profile></section></section></section></section></section></section></section><section><span><span>信息来源｜DeepSeek、X、机器之心、量子位</span></span></section><p data-mpa-powered-by="yiban.io"><span><span>上周五，DeepSeek 发推说本周将是开源周（OpenSourceWeek），并将连续开源五个软件库。</span></span></p><section><span><span>第一天，<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247701831&amp;idx=1&amp;sn=1bd02423f81735222d6e72e0341e8aa3&amp;scene=21#wechat_redirect" textvalue="他们开源了一款用于 Hopper GPU 的高效型 MLA 解码核：FlashMLA" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" hasload="1">他们<span>开源了一款用于 Hopper GPU 的高效型 MLA 解码核：FlashMLA</span></a><span>。</span></span></span></section><section><span><span><br></span></span></section><section><span><span><span>第二天，<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247701931&amp;idx=1&amp;sn=0cb2b85ae0b441a9e65bc5b65ffa201d&amp;scene=21#wechat_redirect" textvalue="他们开源了首个专为 MoE（专家混合）模型训练和推理打造的开源 EP 通信库：DeepEP" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" hasload="1">他们开源了<span>首个专为 MoE（专家混合）模型训练和推理打造的开源 EP 通信库：<span>DeepEP</span></span></a><span><span></span>。</span></span></span></span></section><section><span><span><span><span><br></span></span></span></span></section><section><span><span>第三天，<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247701991&amp;idx=1&amp;sn=db9606ed1a1ab570b862be70b38d2a62&amp;scene=21#wechat_redirect" textvalue="他们开源了一款支持密集型和专家混合（MoE）GEMM 的 FP8 GEMM 库：DeepGEMM。" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">他们开源了一款支持密集型和专家混合（MoE）GEMM 的 FP8 GEMM 库：<span>DeepGEMM。</span></a></span></span><br></section><section><br></section><section><span>就在刚刚，DeepSeek <span>开源周</span>第四天，一口气开源了三个代码库。</span></section><p><span></span></p><section><span><p><span><strong>DualPipe</strong>：</span><span>是</span>一种双向流水线并行算法，用于 V3/R1 训练中的计算-通信重叠；<span><strong>EPLB</strong>：</span><span>用于 V3/R1 的专家并行负载均衡器；</span><span><span><strong>profile-data</strong></span><span>：</span></span><span>训练和推理框架的分析数据。</span></p><p><span><br></span></p><p><span></span><span>DualPipe 通过重叠计算和通信来减少训练的空闲时间，EPLB 平衡了工作负载，使得几乎没有 GPU</span> <span><span>闲置的情况，而公布 profile-data 是为</span></span><span><span>了帮助社区更好地理解通信 - 计算重叠策略和底层实现细节。</span></span></p><p><br></p><section><img data-galleryid="" data-imgfileid="100218403" data-ratio="0.9574074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/vI9nYe94fsG0NuVTbKjD4hyyC3EWREW9x7tzXC5tYPM2qCvoLzh0SICjKvtwIjVLEaNDpQR7Y7c6nz2Y12KjlA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/vI9nYe94fsG0NuVTbKjD4hyyC3EWREW9x7tzXC5tYPM2qCvoLzh0SICjKvtwIjVLEaNDpQR7Y7c6nz2Y12KjlA/640?wx_fmt=png&amp;from=appmsg"></section><section><br></section><ul><li><section><span>DualPipe 链接：https://github.com/deepseek-ai/DualPipe</span></section></li><li><section><span>EPLB 链接：https://github.com/deepseek-ai/eplb</span></section></li><li><section><span>profile-data 链接：ht</span><span>tps://github.com/deepseek-ai/profile-data</span></section></li></ul><section><span></span></section><section><span><br></span></section><section><span></span><span>值得一提的是，在 DualPipe 的 GitHub 上，DeepSeek 创始人梁文锋位列开发者行列之中。</span><span></span></section><section><span><br></span></section><p><img data-galleryid="" data-imgfileid="100218404" data-ratio="0.15833333333333333" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/vI9nYe94fsG0NuVTbKjD4hyyC3EWREW9Whw0EicM08GD4CPEs2M0M2tmtEiccgLL11XEPeYKZMev3PfkQtSJvr3A/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/vI9nYe94fsG0NuVTbKjD4hyyC3EWREW9Whw0EicM08GD4CPEs2M0M2tmtEiccgLL11XEPeYKZMev3PfkQtSJvr3A/640?wx_fmt=png&amp;from=appmsg"></p></span></section><h2 data-tool="mdnice编辑器"></h2><p><span>通俗理解三个代码库</span></p><p><span>技术语言可能不好理解，我们来看一下网友给出的比喻：</span></p><section><br></section><section><span>想象一下，训练一个庞大的语言模型就像指挥一个交响乐团。每个 GPU 就像一位音乐家，执行其分配的计算任务，而训练框架则充当指挥，保持一切完美同步。在典型设置中，音乐家们可能需要等待彼此，造成尴尬的停顿。这些延迟，被称为流水线气泡，会减慢整个过程。</span></section><section><br></section><section><span>DualPipe 通过允许不同部分并行工作来消除这些低效，就像弦乐部演奏的同时铜管部也在排练。这种努力的重叠确保没有停机时间。</span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218409" data-ratio="1.0527777777777778" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpoZnHU5weKqL353eB43YnQcu0rS9IicUcny5oMClXSdOgkWGQNQunjOA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpoZnHU5weKqL353eB43YnQcu0rS9IicUcny5oMClXSdOgkWGQNQunjOA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><span>有网友评价说，「DualPipe 不仅仅是另一种流水线并行实现。它解决的根本问题是标准流水线并行中固有的低效率。传统方法如 1F1B（一次前向，一次后向）甚至 Zero Bubble（ZB1P）都存在流水线气泡 —— 即各计算单元等待数据时的空闲时间。DualPipe 旨在实现前向和后向计算 - 通信阶段的完全重叠，最大限度地减少了这些气泡。」</span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218407" data-ratio="0.45740740740740743" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpSxncVJAknf9JpmWLUsdORrWPI32ibEtI2TXXSK0fQAEianaOKFEUbrvQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpSxncVJAknf9JpmWLUsdORrWPI32ibEtI2TXXSK0fQAEianaOKFEUbrvQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><span>而关于 EPLB，我们可以这么理解：传统的数据并行就像给每个人一份整个项目的副本 —— 既浪费又缓慢。专家并行（EP），即每个专家驻留在不同的 GPU 上，如果可以平衡负载，则效率要高得多。EPLB 就是为了解决这种专家失衡问题而设计的。这不仅仅是分配专家；它是关于智能地分配它们，以最大限度地提高 GPU 利用率和最小化通信开销。</span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218406" data-ratio="0.43333333333333335" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkp2btZXkAK49zYctR3bOvs3nKeBibtOAUWMQBxWx5I7ph19tLlhw0NJicw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkp2btZXkAK49zYctR3bOvs3nKeBibtOAUWMQBxWx5I7ph19tLlhw0NJicw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><span>到现在为止，DeepSeek 似乎已经把发布 V3、R1 模型时未公布的很多训练、部署细节也公开了出来。人们不仅可以在此基础上更好地使用 DeepSeek 模型，在使用其他大模型时也能获得助益。</span></section><section><br></section><section><span>明天周五，是开源周的最后一天，DeepSeek 有可能用 R2 来收尾吗？</span></section><h2 data-tool="mdnice编辑器"></h2><p><span>DeepSeek官方介绍</span></p><p><span>接着，让我们看看 DeepSeek 对于三个项目的官方介绍。</span></p><section><br></section><section><strong><span><strong>DualPipe：双向流水线并行算法</strong></span></strong></section><section><br></section><section><span>DualPipe 是在 DeepSeek-V3 技术报告中引入的一种创新的双向流水线并行算法。它实现了前向和后向计算 - 通信阶段的完全重叠，同时减少了流水线气泡。有关计算 - 通信重叠的详细信息，请参阅配置文件数据：https://github.com/deepseek-ai/profile-data</span></section><section><br></section><section><span><strong>调度</strong></span></section><section><span><strong><br></strong></span></section><section><span><strong><img alt="image.png" data-imgfileid="100218405" data-ratio="0.17407407407407408" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpVCBqlQVUhFJGINhGoossC07T12LxO4otPG89L6iaXxhMOHbiaZ7XGKIw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpVCBqlQVUhFJGINhGoossC07T12LxO4otPG89L6iaXxhMOHbiaZ7XGKIw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></strong></span></section><section><span></span></section><section><br></section><section><span>DualPipe 调度示例：8 个 流水线并行（PP）级别和 20 个双向 micro-batch。反向的 micro-batch 与前向的 micro-batch 对称，因此图中省略了它们的 batch ID 。被共享的黑色边框包围的两个单元格具有相互重叠的计算和通信。</span></section><section><br></section><section><span>有网友制作了 DualPipe 与其他两种方法 ——1F1B and ZB1P 的对比图：    </span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218414" data-ratio="0.8055555555555556" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpianHib1vG9DCknyR7VQwy2IUhFM7LgG3dguOBRWiayQr7XKRtmKIkPsVA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpianHib1vG9DCknyR7VQwy2IUhFM7LgG3dguOBRWiayQr7XKRtmKIkPsVA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><span><strong>Pipeline 气泡和内存使用情况比较</strong></span></section><section><span><strong><br></strong></span></section><section><span><strong><img alt="image.png" data-imgfileid="100218411" data-ratio="0.34629629629629627" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkp1nMLeCgngIwO98pp5kAsnCv4o5SDWqDVdiapJTLDDxAkSsW5okzrmVg/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkp1nMLeCgngIwO98pp5kAsnCv4o5SDWqDVdiapJTLDDxAkSsW5okzrmVg/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></strong></span></section><section><br></section><section><span>𝐹 表示前向数据块的执行时间，𝐵 表示完整后向数据块的执行时间，𝑊 表示「权重后向」数据块的执行时间，𝐹&amp;𝐵 表示两个相互重叠的前向和后向数据块的执行时间。</span></section><section><br></section><section><span>DualPipe由Jiashi Li、Chengqi Deng、梁文锋创建和开发。更多信息请参见GitHub代码库。</span></section><section><span></span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218412" data-ratio="0.3574074074074074" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpVkGxzhDRUrZp3sZNI50z1Fgu57Y5QF2B6UUrM3aLONSECxTGbuNs9A/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpVkGxzhDRUrZp3sZNI50z1Fgu57Y5QF2B6UUrM3aLONSECxTGbuNs9A/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><strong><span><strong><span><strong>EPLB：</strong></span></strong><strong>负载均衡算法</strong></span></strong></section><section><span></span></section><section><br></section><section><span>在使用专家并行（Expert Parallelism，EP）时，不同的专家被分配到不同的 GPU 上。由于不同专家的负载可能会根据当前工作负载而变化，保持不同 GPU 之间的负载平衡非常重要。正如 DeepSeek-V3 论文中所描述的，工程师们采用了冗余专家策略，复制高负载的专家。然后，DeepSeek 通过启发式方法将这些复制的专家打包到 GPU 上，以确保不同 GPU 之间的负载平衡。</span></section><section><br></section><section><span>此外，得益于 DeepSeek-V3 中使用的组限制专家路由（group-limited expert routing），DeepSeek 工程师还尽可能地将同一组的专家放置在同一节点上，以减少节点间的数据传输。</span></section><section><br></section><section><span>为了便于复现和部署，DeepSeek 在 eplb.py 中开源了部署的 EP 负载平衡算法。该算法根据估计的专家负载计算出一个平衡的专家复制和放置方案。请注意，预测专家负载的确切方法超出了本仓库的范围。一种常见的方法是使用历史统计数据的移动平均值。</span></section><section><br></section><section><img alt="image.png" data-imgfileid="100218413" data-ratio="0.3962962962962963" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpmNaiaz9X8pWd0cfXvlmBEJvaKcqQEfVaaVkNtYAHkibKTW2YNWntic4iaA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpmNaiaz9X8pWd0cfXvlmBEJvaKcqQEfVaaVkNtYAHkibKTW2YNWntic4iaA/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><strong><span>DeepSeek Infra 中的数据分析</span></strong></section><section><br></section><section><span>DeepSeek 公开分享了自身的训练和推理框架分析数据，以帮助社区更好地了解通信计算重叠策略和低级实现细节。该分析数据是使用 PyTorch Profiler 捕获的。下载后，人们可以通过在 Chrome 浏览器中导航到 chrome://tracing（或在 Edge 浏览器中导航到 edge://tracing）来直接对其进行可视化。</span></section><section><span><br></span></section><section><span><img alt="image.png" data-imgfileid="100218410" data-ratio="0.18055555555555555" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpmPOSnyIzyZEbXDPy84wJhyReeOqibU1u0QzeQeyIOByicibpCnhickjtrw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpmPOSnyIzyZEbXDPy84wJhyReeOqibU1u0QzeQeyIOByicibpCnhickjtrw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></span></section><section><br></section><section><span>训练配置文件数据展示了 DeepSeek 在 DualPipe 中针对一对单独的前向和后向块的重叠策略。每个块包含 4 个 MoE（专家混合）层。并行配置与 DeepSeek-V3 预训练设置一致：EP64、TP1 具有 4K 序列长度。并且为简单起见，在分析过程中不包括 PP 通信。</span></section><section><span><br></span></section><section><span><img alt="image.png" data-imgfileid="100218415" data-ratio="0.21944444444444444" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpsCapqWQDBP3HaoAEU8fmg95jXdxoIB7KxzS62acYoaHKTjNUnResGQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpsCapqWQDBP3HaoAEU8fmg95jXdxoIB7KxzS62acYoaHKTjNUnResGQ/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></span></section><section><br></section><section><span>在推理上，对于预填充，该配置文件采用 EP32 和 TP1（与 DeepSeek V3/R1 的实际在线部署一致），提示长度设置为 4K，每 GPU 的批大小为 16K 个 token。在预填充阶段，DeepSeek 使用两个 micro-batch 来重叠计算和全对全通信，同时确保注意力计算负载在两个微批次之间保持平衡 —— 这意味着同一个提示可以在它们之间拆分。</span></section><section><span><br></span></section><section><span><img alt="image.png" data-imgfileid="100218416" data-ratio="0.2388888888888889" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkphfb1M8f5ibDsvSoKhJpARDWBkU3aNLmjV3guKGrlr5p1ibwqjHQtUKug/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkphfb1M8f5ibDsvSoKhJpARDWBkU3aNLmjV3guKGrlr5p1ibwqjHQtUKug/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></span></section><section><br></section><section><span>对于解码，该配置文件采用 EP128、TP1 和 4K 的提示长度（与实际的在线部署配置非常接近），每个 GPU 的批处理大小为 128 个请求。与预填充类似，解码也利用两个 micro-batch 进行重叠计算和全对全通信。但是，与预填充不同，解码期间的全对全通信不占用 GPU SM：发出 RDMA 消息后，所有 GPU SM 都被释放，系统等待计算完成后全对全通信完成。</span></section><h2 data-tool="mdnice编辑器"></h2><p><span>DeepSeek 错峰优惠，半夜跑 AI 更省钱</span></p><p><span>除了持续开源，DeepSeek 官方在昨天和前天还宣布了两条重要消息：一是恢复 API 开放平台充值；</span><span><span>二是北京时间每日 00:30 至 08:30 的夜间空闲时段，推出错峰优惠活动。</span></span></p><p><span><span></span><img alt="image.png" data-imgfileid="100218418" data-ratio="1.4787037037037036" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpia3icMm74Cs8kKCRJRSAOoFHrs7VNEgj2n6MGEPlK7ZC8AoP95cZeqaw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibj2f0JFZejtEvD1sQT6ibkpia3icMm74Cs8kKCRJRSAOoFHrs7VNEgj2n6MGEPlK7ZC8AoP95cZeqaw/640?wx_fmt=other&amp;from=appmsg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"><br></span><br><span>（利好夜猫子&amp;歪果仁？）<br></span></p><p><span>官方 API 平台地址：<br><span>https://platform.deepseek.com/usage</span></span></p><p><span><br></span></p><section><img data-backh="234" data-backw="578" data-imgfileid="100218419" data-ratio="0.40555555555555556" data-w="900" data-src="https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsGxu3P5YibTO899okS0X9WaLmQCtia4U8Eu1xWCz9t8Qtq9PH6T1bTcxibiaCIkGzAxpeRkRFYqibVmwSw/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" alt="图片" src="https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsGxu3P5YibTO899okS0X9WaLmQCtia4U8Eu1xWCz9t8Qtq9PH6T1bTcxibiaCIkGzAxpeRkRFYqibVmwSw/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp"><strong><span><span>一起“</span><span><strong><span>点</span></strong></span><span><strong><span>赞<span>”</span></span></strong></span><strong><span>三连</span></strong><span>↓</span></span></strong></section><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/vd1VbaYF_n7pXDbjfPP5Yw",target="_blank" rel="noopener noreferrer">原文链接</a>
