---
title: "Python å®ç° GRPO ç®€ç‰ˆ"
date: 2025-04-18T02:34:42Z
draft: ["false"]
tags: [
  "fetched",
  "æ•°æ®STUDIO"
]
categories: ["Duty"]
---
Python å®ç° GRPO ç®€ç‰ˆ by æ•°æ®STUDIO
------
<div><p data-mpa-powered-by="yiban.io"><span leaf=""><img data-ratio="0.1782178217821782" data-type="gif" data-w="606" data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibSBAB7MzqzBARx8T3TBZruGNeET47qhWwjg4BqHeZ1x5mGWvyVXy4pJclLnUblwlbcScjxFGNP5A/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibSBAB7MzqzBARx8T3TBZruGNeET47qhWwjg4BqHeZ1x5mGWvyVXy4pJclLnUblwlbcScjxFGNP5A/640?wx_fmt=gif"></span><span leaf=""><br></span></p><section data-tool="mdniceç¼–è¾‘å™¨" data-website="https://www.mdnice.com"><section nodeleaf=""><img data-ratio="0.15255813953488373" data-type="gif" data-w="1075" data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibWWVA1RARlHw5jnibnfd6JGic5gARmlWo6uUAWD1ibWdqOWynFaJMcVWXw42637bhaKOybTxQgib4DEQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibWWVA1RARlHw5jnibnfd6JGic5gARmlWo6uUAWD1ibWdqOWynFaJMcVWXw42637bhaKOybTxQgib4DEQ/640?wx_fmt=gif"></section><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">ä»Šå¤©æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨GRPOçš„å®ç°ã€‚å…ˆç®€è¦ä»‹ç»è¿™ä¸€æ¦‚å¿µï¼Œè®¨è®ºæ–¹æ³•ï¼Œç„¶åå¼€å§‹å…·ä½“å®ç°ã€‚</span></p><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf=""><img data-imgfileid="100106564" data-type="png" data-ratio="0.5981481481481481" data-w="1080" data-src="https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7icmiaFXCvSicjxy977LFVaPO6FFDjMrfRP0K4qyQ5rO0uhMqEjE3TwYFbtUnKjeQreiaExmVGUCt7gicA/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7icmiaFXCvSicjxy977LFVaPO6FFDjMrfRP0K4qyQ5rO0uhMqEjE3TwYFbtUnKjeQreiaExmVGUCt7gicA/640?wx_fmt=png&amp;from=appmsg"></span></p><h2 data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><span></span><span><span leaf="">ä»€ä¹ˆæ˜¯GRPOï¼Ÿ</span></span><span></span></h2><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">GRPOæ˜¯ä¸€ç§è®­ç»ƒæŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡æ•æ‰ç‰¹å®šåå¥½çš„å¥–åŠ±å‡½æ•°æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹ã€‚ä¸å…¶ä»–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚PPOæˆ–RLHFï¼‰ä¸åŒï¼ŒGRPOä¸éœ€è¦å¤æ‚çš„è¯„åˆ¤æ¨¡å‹å’Œå¤§é‡è®¡ç®—èµ„æºï¼Œè€Œæ˜¯ç›´æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡åœ¨ç”Ÿæˆçš„å“åº”ç»„å†…è®¡ç®—ç›¸å¯¹ä¼˜åŠ¿æ¥å®ç°ç›®æ ‡ã€‚</span></p><h2 data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><span></span><span><span leaf="">GRPOçš„å…³é”®ç‰¹ç‚¹</span></span><span></span></h2><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">GRPOçš„ç‹¬ç‰¹ä¹‹å¤„</span></span><span></span></h3><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">GRPOæ˜¯ä¸€ç§æ–°å…´çš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š</span></p><ul><li><section><strong><span leaf="">ç›´æ¥ä¼˜åŒ–</span></strong><span leaf="">ï¼šä¸åŒäºéœ€è¦ç‹¬ç«‹å¥–åŠ±æ¨¡å‹çš„æ–¹æ³•ï¼ŒGRPOç›´æ¥ä½¿ç”¨æ˜¾å¼å¥–åŠ±å‡½æ•°ä¼˜åŒ–è¯­è¨€æ¨¡å‹ã€‚</span></section></li><li><section><strong><span leaf="">å¤šå¥–åŠ±ä¿¡å·</span></strong><span leaf="">ï¼šå¯ä»¥å®šä¹‰å¤šä¸ªå¥–åŠ±å‡½æ•°ï¼Œé’ˆå¯¹ç”Ÿæˆå†…å®¹çš„ä¸åŒæ–¹é¢ï¼ˆå¦‚æ­£ç¡®æ€§ã€æ ¼å¼ã€é£æ ¼ï¼‰ã€‚</span></section></li><li><section><strong><span leaf="">æ¢ç´¢æ•ˆç‡</span></strong><span leaf="">ï¼šGRPOé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ºæ¯ä¸ªæç¤ºç”Ÿæˆå¤šä¸ªè¡¥å…¨å†…å®¹ï¼Œæœ‰æ•ˆæ¢ç´¢è¾“å‡ºç©ºé—´ã€‚</span></section></li></ul><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å¥–åŠ±å‡½æ•°</span></span><span></span></h3><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">ä»£ç å®ç°äº†å¤šä¸ªååŒå·¥ä½œçš„å¥–åŠ±å‡½æ•°ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹ï¼š</span></p><ul><li><section><strong><span leaf="">correctness_reward_func</span></strong><span leaf="">ï¼šå½“æ¨¡å‹æå–çš„ç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆåŒ¹é…æ—¶ï¼Œå¥–åŠ±2.0åˆ†ã€‚è¿™æ˜¯äº‹å®æ­£ç¡®æ€§çš„ä¸»è¦å­¦ä¹ ä¿¡å·ã€‚</span></section></li><li><section><strong><span leaf="">int_reward_func</span></strong><span leaf="">ï¼šå½“ç­”æ¡ˆæ˜¯æ•°å­—æ—¶å¥–åŠ±0.5åˆ†ï¼Œé€‚ç”¨äºæ•°å­¦é—®é¢˜ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ•°å€¼å“åº”ã€‚</span></section></li><li><section><strong><span leaf="">soft_format_reward_funcå’Œstrict_format_reward_func</span></strong><span leaf="">ï¼šå¥–åŠ±æ­£ç¡®çš„XMLæ ¼å¼ï¼ˆ0.5åˆ†ï¼‰ï¼Œæ•™å¯¼æ¨¡å‹ä½¿ç”¨æ­£ç¡®çš„æ ‡ç­¾ç»“æ„å“åº”ã€‚</span></section></li><li><section><strong><span leaf="">xmlcount_reward_func</span></strong><span leaf="">ï¼šä¸ºæ¯ä¸ªæ­£ç¡®ä½¿ç”¨çš„XMLæ ‡ç­¾æä¾›éƒ¨åˆ†å¥–åŠ±ï¼ˆæ¯ä¸ªæ ‡ç­¾0.125åˆ†ï¼‰ï¼Œå½¢æˆå¹³æ»‘çš„å­¦ä¹ æ¢¯åº¦ã€‚</span></section></li></ul><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å®ç°ç»„ä»¶</span></span><span></span></h3><ul><li><section><strong><span leaf="">å¥–åŠ±å‡½æ•°</span></strong><span leaf="">ï¼šæ ¹æ®ç‰¹å®šæ ‡å‡†è¯„ä¼°æ¨¡å‹è¾“å‡ºï¼š</span></section></li><ul><li><section><span leaf="">æ­£ç¡®æ€§ï¼šæ£€æŸ¥æå–çš„ç­”æ¡ˆæ˜¯å¦ä¸çœŸå®ç­”æ¡ˆåŒ¹é…ã€‚</span></section></li><li><section><span leaf="">æ ¼å¼éµå¾ªï¼šç¡®ä¿å“åº”ç¬¦åˆè¯·æ±‚çš„XMLæ ¼å¼ã€‚</span></section></li><li><section><span leaf="">æ•´æ•°æ£€æµ‹ï¼šå¥–åŠ±æ•°å€¼ç­”æ¡ˆã€‚</span></section></li></ul><li><section><strong><span leaf="">æ•°æ®é›†å‡†å¤‡</span></strong><span leaf="">ï¼šä½¿ç”¨GSM8Kï¼ˆæ•°å­¦åº”ç”¨é¢˜ï¼‰æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œç‰¹å®šæ ¼å¼åŒ–ã€‚</span></section></li><li><section><strong><span leaf="">è®­ç»ƒé…ç½®</span></strong><span leaf="">ï¼šä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚</span></section></li></ul><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">è®­ç»ƒè¿‡ç¨‹</span></span><span></span></h3><ul><li><section><span leaf="">å¯¹äºæ•°æ®é›†ä¸­çš„æ¯ä¸ªæç¤ºï¼Œæ¨¡å‹ç”Ÿæˆå¤šä¸ªè¡¥å…¨å†…å®¹ï¼ˆç”±</span><strong><span leaf="">num_generations</span></strong><span leaf="">è®¾ç½®ï¼Œä»£ç ä¸­ä¸º4ï¼‰ã€‚</span></section></li><li><section><span leaf="">æ¯ä¸ªè¡¥å…¨å†…å®¹ç”±æ‰€æœ‰å¥–åŠ±å‡½æ•°è¯„ä¼°ã€‚</span></section></li><li><section><span leaf="">å¥–åŠ±ç”¨äºæ›´æ–°æ¨¡å‹æƒé‡ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´é«˜å¥–åŠ±çš„è¾“å‡ºã€‚</span></section></li><li><section><span leaf="">æ­¤è¿‡ç¨‹æŒç»­æŒ‡å®šçš„å‘¨æœŸæ•°ã€‚</span></section></li></ul><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å‚æ•°é«˜æ•ˆå¾®è°ƒ</span></span><span></span></h3><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">æˆ‘ä»¬ä½¿ç”¨LoRAï¼ˆä½ç§©é€‚åº”ï¼‰é«˜æ•ˆå¾®è°ƒæ¨¡å‹ã€‚LoRAå‘æ³¨æ„åŠ›å±‚æ·»åŠ å°å‹å¯è®­ç»ƒçš„â€œé€‚é…å™¨â€çŸ©é˜µï¼Œå¤§å¹…å‡å°‘è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆé€šå¸¸&gt;99%ï¼‰ã€‚</span><strong><span leaf="">peft_config</span></strong><span leaf="">å®šä¹‰äº†ç›®æ ‡å±‚å’Œé€‚é…å™¨çš„ç§©ã€‚</span></p><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å®æ–½è€ƒè™‘</span></span><span></span></h3><ul><li><section><span leaf="">ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆQwen2.5-1.5B-Instructï¼‰ä»¥é€‚åº”å†…å­˜é™åˆ¶ã€‚</span></section></li><li><section><span leaf="">å‡å°æ‰¹æ¬¡å¤§å°å’Œç”Ÿæˆæ•°é‡ä»¥ç®¡ç†å†…å­˜ä½¿ç”¨ï¼Œå¹¶ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†å­é›†ï¼ˆ20ä¸ªç¤ºä¾‹ï¼‰è¿›è¡Œå¿«é€Ÿå®éªŒã€‚</span></section></li><li><section><span leaf="">æµ‹è¯•ä»£ç å¯åœ¨è®­ç»ƒåç«‹å³è¯„ä¼°ç»“æœã€‚å¯é€šè¿‡å¢åŠ </span><strong><span leaf="">max_samples</span></strong><span leaf="">è¡Œæ›´å…¨é¢çš„è®­ç»ƒï¼Œæˆ–å°è¯•ä¸åŒçš„å¥–åŠ±å‡½æ•°ã€‚</span></section></li></ul><h2 data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><span></span><span><span leaf="">ä»£ç å®ç°</span></span><span></span></h2><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å®‰è£…æ‰€éœ€åŒ…</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">pip install -q transformers datasets trl peft accelerate</span><span leaf=""><br></span><span leaf="">import re</span><span leaf=""><br></span><span leaf="">import torch</span><span leaf=""><br></span><span leaf="">import numpy as np</span><span leaf=""><br></span><span leaf="">from datasets import load_dataset, Dataset</span><span leaf=""><br></span><span leaf="">from transformers import AutoTokenizer, AutoModelForCausalLM</span><span leaf=""><br></span><span leaf="">from peft import LoraConfig, get_peft_model</span><span leaf=""><br></span><span leaf="">from trl import GRPOConfig, GRPOTrainer</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å®šä¹‰ç³»ç»Ÿå’Œå“åº”æç¤º</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">SYSTEM_PROMPT =Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å“åº”ï¼š Â </span><span leaf=""><br></span><span leaf="">&lt;reasoning&gt; Â </span><span leaf=""><br></span><span leaf="">... Â </span><span leaf=""><br></span><span leaf="">&lt;/reasoning&gt; Â </span><span leaf=""><br></span><span leaf="">&lt;answer&gt; Â </span><span leaf=""><br></span><span leaf="">... Â </span><span leaf=""><br></span><span leaf="">&lt;/answer&gt; Â </span><span leaf=""><br></span><span leaf="">"</span></span><span><span leaf="">""</span></span><span leaf=""><br></span><span leaf=""><br></span><span leaf="">XML_COT_FORMAT =Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">&lt;reasoning&gt; Â </span><span leaf=""><br></span><span leaf="">{reasoning} Â </span><span leaf=""><br></span><span leaf="">&lt;/reasoning&gt; Â </span><span leaf=""><br></span><span leaf="">&lt;answer&gt; Â </span><span leaf=""><br></span><span leaf="">{answer} Â </span><span leaf=""><br></span><span leaf="">&lt;/answer&gt; Â </span><span leaf=""><br></span><span leaf="">"</span></span><span><span leaf="">""</span></span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">æå–ç­”æ¡ˆçš„è¾…åŠ©å‡½æ•°</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">def extract_xml_answer(text: str) -&gt; str: Â </span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">"ä»XMLæ ¼å¼çš„å“åº”ä¸­æå–ç­”æ¡ˆéƒ¨åˆ†ã€‚"</span></span><span><span leaf="">""</span></span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span><span leaf="">"&lt;answer&gt;"</span></span><span leaf="">Â notÂ </span><span><span leaf="">in</span></span><span leaf="">Â text orÂ </span><span><span leaf="">"&lt;/answer&gt;"</span></span><span leaf="">Â notÂ </span><span><span leaf="">in</span></span><span leaf="">Â text: Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">return</span></span><span><span leaf="">""</span></span><span leaf=""><br></span><span leaf="">Â  Â  answer = text.split(</span><span><span leaf="">"&lt;/answer&gt;"</span></span><span leaf="">)[-1] Â </span><span leaf=""><br></span><span leaf="">Â  Â  answer = answer.split(</span><span><span leaf="">"&lt;answer&gt;"</span></span><span leaf="">)[0] Â </span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â answer.strip() Â </span><span leaf=""><br></span><span leaf=""><br></span><span leaf="">def extract_hash_answer(text: str) -&gt; str: Â </span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">"ä»GSM8Kæ ¼å¼ä¸­æå–ç­”æ¡ˆï¼ˆ###æ ‡è®°ä¹‹åï¼‰ã€‚"</span></span><span><span leaf="">""</span></span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span><span leaf="">"####"</span></span><span leaf="">Â notÂ </span><span><span leaf="">in</span></span><span leaf="">Â text: Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">return</span></span><span><span leaf="">""</span></span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â text.split(</span><span><span leaf="">"###"</span></span><span leaf="">)[1].strip().replace(</span><span><span leaf="">"."</span></span><span leaf="">,Â </span><span><span leaf="">""</span></span><span leaf="">).replace(</span><span><span leaf="">"$"</span></span><span leaf="">,Â </span><span><span leaf="">""</span></span><span leaf="">)</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">åŠ è½½å¹¶å‡†å¤‡GSM8Kæ•°æ®é›†</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">def get_gsm8k_questions(split=</span><span><span leaf="">"train"</span></span><span leaf="">, max_samples=100) -&gt; Dataset: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  åŠ è½½GSM8Kæ•°æ®é›†å¹¶æ ¼å¼åŒ–ä¸ºGRPOè®­ç»ƒæ‰€éœ€å½¢å¼ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  å‚æ•°ï¼š Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  split: ä½¿ç”¨çš„æ•°æ®é›†åˆ’åˆ†ï¼ˆtrain, testï¼‰ Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  max_samples: ä½¿ç”¨çš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿå®éªŒï¼‰ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  data = load_dataset(</span><span><span leaf="">'openai/gsm8k'</span></span><span leaf="">,Â </span><span><span leaf="">'main'</span></span><span leaf="">)[split] Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># é™åˆ¶æ•°æ®é›†å¤§å°ä»¥åŠ å¿«å®éªŒ Â </span></span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â max_samples and max_samples &lt; len(data): Â </span><span leaf="">Â  Â  Â  Â  data = data.select(range(max_samples)) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># æ ¼å¼åŒ–æ•°æ®ä¸ºæ‰€éœ€çš„æç¤ºç»“æ„ Â </span></span><span leaf="">Â  Â  data = data.map(lambda x: { Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">'prompt'</span></span><span leaf="">: [ Â </span><span leaf="">Â  Â  Â  Â  Â  Â  {</span><span><span leaf="">'role'</span></span><span leaf="">:Â </span><span><span leaf="">'system'</span></span><span leaf="">,Â </span><span><span leaf="">'content'</span></span><span leaf="">: SYSTEM_PROMPT}, Â </span><span leaf="">Â  Â  Â  Â  Â  Â  {</span><span><span leaf="">'role'</span></span><span leaf="">:Â </span><span><span leaf="">'user'</span></span><span leaf="">,Â </span><span><span leaf="">'content'</span></span><span leaf="">: x[</span><span><span leaf="">'question'</span></span><span leaf="">]} Â </span><span leaf="">Â  Â  Â  Â  ], Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">'answer'</span></span><span leaf="">: extract_hash_answer(x[</span><span><span leaf="">'answer'</span></span><span leaf="">]) Â </span><span leaf="">Â  Â  }) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â data</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">å¥–åŠ±å‡½æ•°</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">def correctness_reward_func(prompts, completions, answer, **kwargs): Â </span><span leaf=""><br></span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  æ£€æŸ¥æå–çš„ç­”æ¡ˆæ˜¯å¦ä¸çœŸå®ç­”æ¡ˆåŒ¹é…çš„å¥–åŠ±å‡½æ•°ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  æ­£ç¡®ç­”æ¡ˆè¿”å›2.0ï¼Œå¦åˆ™è¿”å›0.0ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  responses = [completion[0][</span><span><span leaf="">'content'</span></span><span leaf="">]Â </span><span><span leaf="">for</span></span><span leaf="">Â completionÂ </span><span><span leaf="">in</span></span><span leaf="">Â completions] Â </span><span leaf="">Â  Â  q = prompts[0][-1][</span><span><span leaf="">'content'</span></span><span leaf="">] Â </span><span leaf="">Â  Â  extracted_responses = [extract_xml_answer(r)Â </span><span><span leaf="">for</span></span><span leaf="">Â rÂ </span><span><span leaf="">in</span></span><span leaf="">Â responses] Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># æ‰“å°è°ƒè¯•ä¿¡æ¯ Â </span></span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â kwargs.get(</span><span><span leaf="">'debug'</span></span><span leaf="">, False) and len(responses) &gt; 0: Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">'-'</span></span><span leaf="">*20) Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"é—®é¢˜ï¼š\n{q}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"\nçœŸå®ç­”æ¡ˆï¼š\n{answer[0]}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"\næ¨¡å‹å“åº”ï¼š\n{responses[0]}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â  Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"\næå–çš„ç­”æ¡ˆï¼š\n{extracted_responses[0]}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â [2.0Â </span><span><span leaf="">if</span></span><span leaf="">Â r == aÂ </span><span><span leaf="">else</span></span><span leaf="">Â 0.0Â </span><span><span leaf="">for</span></span><span leaf="">Â r, aÂ </span><span><span leaf="">in</span></span><span leaf="">Â zip(extracted_responses, answer)] Â </span><span leaf="">def int_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf="">float</span></span><span leaf="">]: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  æ£€æŸ¥æå–çš„ç­”æ¡ˆæ˜¯å¦ä¸ºæ•°å­—çš„å¥–åŠ±å‡½æ•°ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  æ•´æ•°ç­”æ¡ˆè¿”å›0.5ï¼Œå¦åˆ™è¿”å›0.0ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  responses = [completion[0][</span><span><span leaf="">'content'</span></span><span leaf="">]Â </span><span><span leaf="">for</span></span><span leaf="">Â completionÂ </span><span><span leaf="">in</span></span><span leaf="">Â completions] Â </span><span leaf="">Â  Â  extracted_responses = [extract_xml_answer(r)Â </span><span><span leaf="">for</span></span><span leaf="">Â rÂ </span><span><span leaf="">in</span></span><span leaf="">Â responses] Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â [0.5Â </span><span><span leaf="">if</span></span><span leaf="">Â r.isdigit()Â </span><span><span leaf="">else</span></span><span leaf="">Â 0.0Â </span><span><span leaf="">for</span></span><span leaf="">Â rÂ </span><span><span leaf="">in</span></span><span leaf="">Â extracted_responses] Â </span><span leaf="">def strict_format_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf="">float</span></span><span leaf="">]: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  æ£€æŸ¥è¡¥å…¨å†…å®¹æ˜¯å¦å®Œå…¨ç¬¦åˆæ ¼å¼çš„å¥–åŠ±å‡½æ•°ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  åŒ¹é…æ ¼å¼è¿”å›0.5ï¼Œå¦åˆ™è¿”å›0.0ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  pattern = r</span><span><span leaf="">"^\n&lt;reasoning&gt;.*?&lt;/reasoning&gt;\n\n&lt;answer&gt;.*?&lt;/answer&gt;\n$"</span></span><span leaf="">Â  Â  responses = [completion[0][</span><span><span leaf="">'content'</span></span><span leaf="">]Â </span><span><span leaf="">for</span></span><span leaf="">Â completionÂ </span><span><span leaf="">in</span></span><span leaf="">Â completions] Â </span><span leaf="">Â  Â  matches = [bool(re.search(pattern, r, flags=re.DOTALL))Â </span><span><span leaf="">for</span></span><span leaf="">Â rÂ </span><span><span leaf="">in</span></span><span leaf="">Â responses] Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â [0.5Â </span><span><span leaf="">if</span></span><span leaf="">Â matchÂ </span><span><span leaf="">else</span></span><span leaf="">Â 0.0Â </span><span><span leaf="">for</span></span><span leaf="">Â matchÂ </span><span><span leaf="">in</span></span><span leaf="">Â matches] Â </span><span leaf="">def soft_format_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf="">float</span></span><span leaf="">]: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  å®½æ¾çš„æ ¼å¼æ£€æŸ¥å¥–åŠ±å‡½æ•°ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  åŒ¹é…æ ¼å¼è¿”å›0.5ï¼Œå¦åˆ™è¿”å›0.0ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  pattern = r</span><span><span leaf="">"&lt;reasoning&gt;.*?&lt;/reasoning&gt;.*?&lt;answer&gt;.*?&lt;/answer&gt;"</span></span><span leaf="">Â  Â  responses = [completion[0][</span><span><span leaf="">'content'</span></span><span leaf="">]Â </span><span><span leaf="">for</span></span><span leaf="">Â completionÂ </span><span><span leaf="">in</span></span><span leaf="">Â completions] Â </span><span leaf="">Â  Â  matches = [bool(re.search(pattern, r, flags=re.DOTALL))Â </span><span><span leaf="">for</span></span><span leaf="">Â rÂ </span><span><span leaf="">in</span></span><span leaf="">Â responses] Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â [0.5Â </span><span><span leaf="">if</span></span><span leaf="">Â matchÂ </span><span><span leaf="">else</span></span><span leaf="">Â 0.0Â </span><span><span leaf="">for</span></span><span leaf="">Â matchÂ </span><span><span leaf="">in</span></span><span leaf="">Â matches] Â </span><span leaf="">def count_xml(text) -&gt;Â </span><span><span leaf="">float</span></span><span leaf="">: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  ç»Ÿè®¡XMLæ ‡ç­¾å¹¶ä¸ºæ¯ä¸ªæ­£ç¡®æ”¾ç½®çš„æ ‡ç­¾æä¾›éƒ¨åˆ†å¥–åŠ±ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  count = 0.0 Â </span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â text.count(</span><span><span leaf="">"&lt;reasoning&gt;"</span></span><span leaf="">) == 1: Â </span><span leaf="">Â  Â  Â  Â  count += 0.125 Â </span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â text.count(</span><span><span leaf="">"&lt;/reasoning&gt;"</span></span><span leaf="">) == 1: Â </span><span leaf="">Â  Â  Â  Â  count += 0.125 Â </span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â text.count(</span><span><span leaf="">"&lt;answer&gt;"</span></span><span leaf="">) == 1: Â </span><span leaf="">Â  Â  Â  Â  count += 0.125 Â </span><span leaf="">Â  Â Â </span><span><span leaf="">if</span></span><span leaf="">Â text.count(</span><span><span leaf="">"&lt;/answer&gt;"</span></span><span leaf="">) == 1: Â </span><span leaf="">Â  Â  Â  Â  count += 0.125 Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â count Â </span><span leaf="">def xmlcount_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf="">float</span></span><span leaf="">]: Â </span><span leaf="">Â  Â Â </span><span><span leaf="">""</span></span><span><span leaf="">" Â </span><span leaf=""><br></span><span leaf="">Â  Â  åŸºäºå“åº”ä¸­XMLæ ‡ç­¾è®¡æ•°çš„å¥–åŠ±å‡½æ•°ã€‚ Â </span><span leaf=""><br></span><span leaf="">Â  Â  "</span></span><span><span leaf="">""</span></span><span leaf="">Â  Â  contents = [completion[0][</span><span><span leaf="">"content"</span></span><span leaf="">]Â </span><span><span leaf="">for</span></span><span leaf="">Â completionÂ </span><span><span leaf="">in</span></span><span leaf="">Â completions] Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â [count_xml(c)Â </span><span><span leaf="">for</span></span><span leaf="">Â cÂ </span><span><span leaf="">in</span></span><span leaf="">Â contents]</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">æ¨¡å‹è®¾ç½®</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">model_name =Â </span><span><span leaf="">"Qwen/Qwen2.5-1.5B-Instruct"</span></span><span leaf="">Â Â </span><span leaf=""><br></span><span><span leaf=""># è®¾ç½®è¾“å‡ºç›®å½•å’Œè¿è¡Œåç§° Â </span></span><span leaf=""><br></span><span leaf="">output_dir =Â </span><span><span leaf="">"outputs/Qwen-1.5B-GRPO"</span></span><span leaf="">Â Â </span><span leaf=""><br></span><span leaf="">run_name =Â </span><span><span leaf="">"Qwen-1.5B-GRPO-gsm8k"</span></span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">é…ç½®GRPOè®­ç»ƒ</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">training_args = GRPOConfig( Â </span><span leaf=""><br></span><span leaf="">Â  Â  output_dir=output_dir, Â </span><span leaf="">Â  Â  run_name=run_name, Â </span><span leaf="">Â  Â  learning_rate=5e-6, Â </span><span leaf="">Â  Â  adam_beta1=0.9, Â </span><span leaf="">Â  Â  adam_beta2=0.99, Â </span><span leaf="">Â  Â  weight_decay=0.1, Â </span><span leaf="">Â  Â  warmup_ratio=0.1, Â </span><span leaf="">Â  Â  lr_scheduler_type=</span><span><span leaf="">'cosine'</span></span><span leaf="">, Â </span><span leaf="">Â  Â  logging_steps=1, Â </span><span leaf="">Â  Â  bf16=False, Â </span><span><span leaf=""># è®¾ç½®ä¸ºFalseï¼Œå› ä¸ºColabä¸æ”¯æŒ Â </span></span><span leaf="">Â  Â  fp16=True, Â Â </span><span><span leaf=""># ä½¿ç”¨fp16ä»¥æé«˜å…¼å®¹æ€§ Â </span></span><span leaf="">Â  Â  per_device_train_batch_size=4, Â </span><span><span leaf=""># å¢åŠ ä»¥å…¼å®¹GRPO Â </span></span><span leaf="">Â  Â  gradient_accumulation_steps=2, Â </span><span leaf="">Â  Â  num_generations=4, Â </span><span><span leaf=""># å¿…é¡»æ˜¯per_device_train_batch_sizeçš„é™¤æ•° Â </span></span><span leaf="">Â  Â  max_prompt_length=256, Â </span><span leaf="">Â  Â  max_completion_length=512, Â </span><span leaf="">Â  Â  num_train_epochs=1, Â </span><span leaf="">Â  Â  save_steps=50, Â </span><span leaf="">Â  Â  max_grad_norm=0.1, Â </span><span leaf="">Â  Â  report_to=</span><span><span leaf="">"none"</span></span><span leaf="">, Â </span><span leaf="">Â  Â  log_on_each_node=False, Â </span><span leaf="">)</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">é…ç½®LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span leaf="">peft_config = LoraConfig( Â </span><span leaf=""><br></span><span leaf="">Â  Â  r=8, Â </span><span><span leaf=""># ä»16å‡å°‘ä»¥é€‚åº”Colabå†…å­˜ Â </span></span><span leaf=""><br></span><span leaf="">Â  Â  lora_alpha=32, Â </span><span leaf=""><br></span><span leaf="">Â  Â  target_modules=[</span><span><span leaf="">"q_proj"</span></span><span leaf="">,Â </span><span><span leaf="">"k_proj"</span></span><span leaf="">,Â </span><span><span leaf="">"v_proj"</span></span><span leaf="">,Â </span><span><span leaf="">"o_proj"</span></span><span leaf="">], Â </span><span><span leaf=""># ç®€åŒ–ç›®æ ‡æ¨¡å— Â </span></span><span leaf=""><br></span><span leaf="">Â  Â  task_type=</span><span><span leaf="">"CAUSAL_LM"</span></span><span leaf="">, Â </span><span leaf=""><br></span><span leaf="">Â  Â  lora_dropout=0.05, Â </span><span leaf=""><br></span><span leaf="">)</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">åŠ è½½å¹¶å‡†å¤‡æ¨¡å‹</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"åŠ è½½æ¨¡å‹ï¼š{model_name}"</span></span><span leaf="">) Â </span><span leaf="">model = AutoModelForCausalLM.from_pretrained( Â </span><span leaf="">Â  Â  model_name, Â </span><span leaf="">Â  Â  torch_dtype=torch.float16, Â </span><span><span leaf=""># ä½¿ç”¨float16è€Œébfloat16 Â </span></span><span leaf="">Â  Â  device_map=</span><span><span leaf="">"auto"</span></span><span leaf="">, Â  Â  Â  Â  Â </span><span><span leaf=""># è®©æ¨¡å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡é…ç½® Â </span></span><span leaf="">Â  Â  low_cpu_mem_usage=True, Â  Â </span><span><span leaf=""># æé«˜å†…å­˜æ•ˆç‡ Â </span></span><span leaf="">Â  Â  trust_remote_code=True Â  Â Â </span><span><span leaf=""># æ–°æ¨¡å‹æœ‰æ—¶éœ€è¦ Â </span></span><span leaf="">) Â </span><span><span leaf=""># åŠ è½½åˆ†è¯å™¨ Â </span></span><span leaf="">tokenizer = AutoTokenizer.from_pretrained(model_name) Â </span><span><span leaf="">if</span></span><span leaf="">Â tokenizer.pad_token is None: Â </span><span leaf="">Â  Â  tokenizer.pad_token = tokenizer.eos_token Â </span><span><span leaf=""># åŠ è½½GSM8Kæ•°æ®é›†çš„å­é›† Â </span></span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"åŠ è½½æ•°æ®é›†..."</span></span><span leaf="">) Â </span><span leaf="">dataset = get_gsm8k_questions(max_samples=20) Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…±{len(dataset)}ä¸ªç¤ºä¾‹"</span></span><span leaf="">)</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">åˆå§‹åŒ–GRPOè®­ç»ƒå™¨</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"åˆå§‹åŒ–GRPOè®­ç»ƒå™¨..."</span></span><span leaf="">) Â </span><span leaf=""><br></span><span leaf=""><br></span><span leaf="">trainer = GRPOTrainer( Â </span><span leaf=""><br></span><span leaf="">Â  Â  model=model, Â </span><span leaf=""><br></span><span leaf="">Â  Â  processing_class=tokenizer, Â </span><span leaf=""><br></span><span leaf="">Â  Â  reward_funcs=[ Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  xmlcount_reward_func, Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  soft_format_reward_func, Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  int_reward_func, Â </span><span leaf=""><br></span><span leaf="">Â  Â  Â  Â  correctness_reward_func Â </span><span leaf=""><br></span><span leaf="">Â  Â  ], Â </span><span leaf=""><br></span><span leaf="">Â  Â  args=training_args, Â </span><span leaf=""><br></span><span leaf="">Â  Â  train_dataset=dataset, Â </span><span leaf=""><br></span><span leaf="">Â  Â  peft_config=peft_config Â </span><span><span leaf=""># å¯ç”¨LoRAè¿›è¡Œé«˜æ•ˆå¾®è°ƒ Â </span></span><span leaf=""><br></span><span leaf="">)</span><span leaf=""><br></span></code></pre><h3 data-tool="mdniceç¼–è¾‘å™¨"><span></span><span><span leaf="">è¿è¡ŒGRPO</span></span><span></span></h3><pre data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><code><span><span leaf=""># å¼€å§‹è®­ç»ƒ Â </span></span><span leaf=""><br></span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"å¼€å§‹GRPOè®­ç»ƒ..."</span></span><span leaf="">) Â </span><span leaf="">trainer.train() Â </span><span><span leaf=""># ä¿å­˜æœ€ç»ˆæ¨¡å‹ Â </span></span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"è®­ç»ƒå®Œæˆã€‚ä¿å­˜æ¨¡å‹..."</span></span><span leaf="">) Â </span><span leaf="">trainer.save_model() Â </span><span><span leaf=""># è®­ç»ƒåæµ‹è¯•æ¨¡å‹ Â </span></span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"\n--- æµ‹è¯•è®­ç»ƒåçš„æ¨¡å‹ ---\n"</span></span><span leaf="">) Â </span><span><span leaf=""># ç”Ÿæˆé¢„æµ‹çš„å‡½æ•° Â </span></span><span leaf="">def generate_prediction(model, tokenizer, question, max_length=512): Â </span><span leaf="">Â  Â  prompt = [ Â </span><span leaf="">Â  Â  Â  Â  {</span><span><span leaf="">'role'</span></span><span leaf="">:Â </span><span><span leaf="">'system'</span></span><span leaf="">,Â </span><span><span leaf="">'content'</span></span><span leaf="">: SYSTEM_PROMPT}, Â </span><span leaf="">Â  Â  Â  Â  {</span><span><span leaf="">'role'</span></span><span leaf="">:Â </span><span><span leaf="">'user'</span></span><span leaf="">,Â </span><span><span leaf="">'content'</span></span><span leaf="">: question} Â </span><span leaf="">Â  Â  ] Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># æ ¼å¼åŒ–æç¤º Â </span></span><span leaf="">Â  Â  messages = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># åˆ†è¯è¾“å…¥ Â </span></span><span leaf="">Â  Â  inputs = tokenizer(messages, return_tensors=</span><span><span leaf="">"pt"</span></span><span leaf="">).to(model.device) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># ç”Ÿæˆå“åº” Â </span></span><span leaf="">Â  Â  with torch.no_grad(): Â </span><span leaf="">Â  Â  Â  Â  outputs = model.generate( Â </span><span leaf="">Â  Â  Â  Â  Â  Â  **inputs, Â </span><span leaf="">Â  Â  Â  Â  Â  Â  max_new_tokens=max_length, Â </span><span leaf="">Â  Â  Â  Â  Â  Â  do_sample=False Â </span><span leaf="">Â  Â  Â  Â  ) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># è§£ç å“åº” Â </span></span><span leaf="">Â  Â  response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">return</span></span><span leaf="">Â response Â </span><span><span leaf=""># æµ‹è¯•æ•°æ®é›†ä¸­çš„å‡ ä¸ªç¤ºä¾‹ Â </span></span><span leaf="">test_examples = dataset.select(range(3)) Â </span><span><span leaf="">for</span></span><span leaf="">Â i, exampleÂ </span><span><span leaf="">in</span></span><span leaf="">Â enumerate(test_examples): Â </span><span leaf="">Â  Â  question = example[</span><span><span leaf="">'prompt'</span></span><span leaf="">][-1][</span><span><span leaf="">'content'</span></span><span leaf="">] Â </span><span leaf="">Â  Â  ground_truth = example[</span><span><span leaf="">'answer'</span></span><span leaf="">] Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"\nç¤ºä¾‹ {i+1}:"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"é—®é¢˜ï¼š{question}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"çœŸå®ç­”æ¡ˆï¼š{ground_truth}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># ç”Ÿæˆé¢„æµ‹ Â </span></span><span leaf="">Â  Â  response = generate_prediction(model, tokenizer, question) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"æ¨¡å‹å“åº”ï¼š{response}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf=""># æå–ç­”æ¡ˆ Â </span></span><span leaf="">Â  Â  extracted_answer = extract_xml_answer(response) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"æå–çš„ç­”æ¡ˆï¼š{extracted_answer}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(f</span><span><span leaf="">"æ˜¯å¦æ­£ç¡®ï¼š{extracted_answer == ground_truth}"</span></span><span leaf="">) Â </span><span leaf="">Â  Â Â </span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"-"</span></span><span leaf="">Â * 50) Â </span><span><span leaf="">print</span></span><span leaf="">(</span><span><span leaf="">"æå®šï¼"</span></span><span leaf="">)</span><span leaf=""><br></span></code></pre><h2 data-tool="mdniceç¼–è¾‘å™¨"><span data-cacheurl="" data-remoteid=""></span><span></span><span><span leaf="">æ€»ç»“</span></span><span></span></h2><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">è¿™ä¸€å®ç°å±•ç¤ºäº†GRPOçš„å·¥ä½œåŸç†ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å®ƒä¼˜åŒ–è¯­è¨€æ¨¡å‹ä»¥é€‚åº”ç‰¹å®šæ ¼å¼å’Œä»»åŠ¡ã€‚æ•°å­¦é—®é¢˜è§£å†³ä»»åŠ¡ä¸XMLæ ¼å¼çš„ç»“åˆï¼Œæ¸…æ™°åœ°ä½“ç°äº†è¯¥æŠ€æœ¯çš„èƒ½åŠ›ã€‚</span></p><p data-tool="mdniceç¼–è¾‘å™¨"><span leaf="">çœŸæ˜¯ä¸€æ¬¡æœ‰è¶£çš„å®è·µï¼</span></p></section><blockquote><p><span leaf="">ä½œè€…ï¼šarjuné“¾æ¥ï¼šhttps://www.k-a.in/grpo-1B.html</span></p><p><span leaf="">ç¼–è¾‘ï¼šAIç¿»è¯‘ã€ã€Œæ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†ã€å…¬ä¼—å·æ¶¦è‰²</span></p></blockquote><section data-mpa-template="t" mpa-from-tpl="t"><section data-mid="" mpa-from-tpl="t"><section data-mid="" mpa-from-tpl="t" nodeleaf=""><img data-ratio="1.452" data-type="gif" data-w="250" data-src="https://mmbiz.qpic.cn/mmbiz_gif/BfjzYen78aJ9jibPqC4UskObNfOib0yfKAaAc91ATL5qjKhtYfWFzia902H2WxfqrGISHpcSnSLK4jyb2qJd54w8w/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/BfjzYen78aJ9jibPqC4UskObNfOib0yfKAaAc91ATL5qjKhtYfWFzia902H2WxfqrGISHpcSnSLK4jyb2qJd54w8w/640?wx_fmt=gif"></section><section data-mid="" mpa-from-tpl="t"><span leaf=""><br></span></section></section></section><h5><span><span leaf="">ğŸ´â€â˜ ï¸å®è—çº§ğŸ´â€â˜ ï¸ åŸåˆ›å…¬ä¼—å·ã€</span><strong><span leaf="">æ•°æ®STUDIO</span></strong><span leaf="">ã€å†…å®¹è¶…çº§ç¡¬æ ¸ã€‚å…¬ä¼—å·ä»¥Pythonä¸ºæ ¸å¿ƒè¯­è¨€ï¼Œå‚ç›´äºæ•°æ®ç§‘å­¦é¢†åŸŸï¼ŒåŒ…æ‹¬</span></span><span><span leaf="">å¯æˆ³</span></span><span><span leaf="">ğŸ‘‰</span><strong><span leaf="">Â </span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974978822768771072&amp;scene=173&amp;from_msgid=2247519294&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">Python</a></span></strong><span><strong><span><span leaf="">ï½œ</span></span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=2023684574089658370&amp;scene=173&amp;from_msgid=2247519619&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">MySQL</a></span></strong><span><strong><span><span leaf="">ï½œ</span></span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974978820940054530&amp;scene=173&amp;from_msgid=2247518366&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">æ•°æ®åˆ†æ</a></span></strong><span><strong><span><span leaf="">ï½œ</span></span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974991176839544834&amp;scene=173&amp;from_msgid=2247519244&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">æ•°æ®å¯è§†åŒ–</a></span></strong><span><strong><span><span leaf="">ï½œ</span></span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1963494160565354497&amp;scene=173&amp;from_msgid=2247512171&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">æœºå™¨å­¦ä¹ ä¸æ•°æ®æŒ–æ˜</a></span></strong><span><strong><span><span leaf="">ï½œ</span></span></strong></span><strong><span leaf=""><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=2318258648965644288&amp;scene=173&amp;from_msgid=2247518366&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue="" target="_blank" linktype="text" data-linktype="2">çˆ¬è™«</a></span></strong><span><span leaf="">Â </span><span><span leaf="">ç­‰ï¼Œä»å…¥é—¨åˆ°è¿›é˜¶ï¼</span></span></span></h5><p><span><span leaf="">é•¿æŒ‰ğŸ‘‡å…³æ³¨- æ•°æ®STUDIO -è®¾ä¸ºæ˜Ÿæ ‡ï¼Œå¹²è´§é€Ÿé€’</span></span><span leaf=""><img data-ratio="0.3351851851851852" data-type="gif" data-w="1080" data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI78ZgGwzt8M0xnekvrATwDWP7y4cdlwy4WOrJSUIqRfncsEYsPYM9wkQ8Gpr57zCpzia124Gb2d7icTQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI78ZgGwzt8M0xnekvrATwDWP7y4cdlwy4WOrJSUIqRfncsEYsPYM9wkQ8Gpr57zCpzia124Gb2d7icTQ/640?wx_fmt=gif"><img data-ratio="0.08703703703703704" data-type="gif" data-w="1080" data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ickLkMzUmaxe4mdegUFLheymDmGI4OiaeeoY4K0ttDRGju4p6F7iaGfSb4H6EDCCCC9bo7KuLiblIdXQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ickLkMzUmaxe4mdegUFLheymDmGI4OiaeeoY4K0ttDRGju4p6F7iaGfSb4H6EDCCCC9bo7KuLiblIdXQ/640?wx_fmt=gif"></span></p><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/EL7ZvtJS7WEeWI5P53qHDA",target="_blank" rel="noopener noreferrer">åŸæ–‡é“¾æ¥</a>
