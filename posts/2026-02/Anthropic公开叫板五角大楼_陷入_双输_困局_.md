---
title: "Anthropic公开叫板五角大楼 陷入“双输”困局？"
date: 2026-02-28T00:06:26Z
draft: ["false"]
tags: [
  "fetched",
  "cnbeta"
]
categories: ["Duty"]
---
Anthropic公开叫板五角大楼 陷入“双输”困局？ by cnbeta
------
<div style="margin-top:10px" class="content" id="artibody"><p>截至周五，Anthropic似乎已陷入必败之境。它必须在美国东部时间下午5：01前做出决定：是否同意让国防部在所有合法场景下无限制使用其模型。若拒绝，国防部长赫格塞思已放话，要么将其列为“供应链风险”，要么援引《国防生产法》强制其服从。</p><div class="article-global"></div><p>																																																					<img src="https://n.sinaimg.cn/tech/transform/58/w550h308/20260227/5d8a-2ca4c69ba08f53439f2aa16335be34d3.png" alt=""></p><p>2025年7月，Anthropic与美国国防部签署了一份价值2亿美元的合同，成为首个将模型集成到涉密网络任务工作流中的AI实验室。<strong>该公司一直在与国防部协商协议条款，并要求对方保证，其技术不会被用于完全自主武器，也不会用于对美国民众的国内大规模监控。</strong></p><p>Anthropic首席执行官达里奥・阿莫迪周四在一份声明中写道：“在少数特定场景下，我们认为AI非但无法捍卫民主价值观，反而会对其造成损害。部分应用场景也完全超出了当前技术能够安全、可靠运行的范畴。”</p><p>国防部寸步不让，谈判陷入僵局，这也成为迄今为止对Anthropic所宣称价值观最受瞩目的考验。多年来，Anthropic精心塑造自身作为安全、负责任部署AI倡导者的形象，与阿莫迪此前任职的OpenAI形成鲜明对比。</p><p><strong>Anthropic是“供应链风险”吗？</strong></p><p>与此同时，Anthropic还面临着巨大压力——需证明其3800亿美元的估值合理性（该估值由大型机构与战略投资者支撑），同时要在模型研发领域保持领先，抵御来自OpenAI、谷歌以及马斯克旗下xAI等对手的竞争。<strong>这三家公司的模型均已被美国国防部采用。</strong></p><p>若屈从于国防部的要求，Anthropic可能会损害自身声誉，疏远员工与客户；但若拒绝向军方无限制开放其模型，短期内可能会损失可观收入，还可能被排除在未来与其他政府合作企业的潜在合作机会之外。</p><p>乔治城大学安全与新兴技术中心高级研究分析师劳伦・卡恩在接受采访时表示：“此事没有赢家，只会让所有人心里都不舒服。”</p><p>五角大楼首席发言人肖恩・帕内尔周四称，国防部“无意”将AI用于完全自主武器，也不会对美国民众实施大规模监控——他指出，这类行为本身就是非法的。他表示，国防部希望Anthropic同意，其模型可被用于“所有合法用途”。</p><p>帕内尔周四在X平台发文称：“这是一个简单、符合常理的要求，能避免Anthropic危及关键军事行动，甚至让我方作战人员陷入风险。<strong>我们绝不会允许任何公司对我们的作战决策方式指手画脚。”</strong></p><p><strong>美国国防部负责研究与工程的副部长、前优步高管</strong>埃米尔・迈克尔周四也在X平台发文，<strong>称阿莫迪是“骗子，还患有上帝情结</strong>”，指责他“只想亲自掌控美国军队”。</p><p>本周早些时候，赫格塞思在与阿莫迪的会面中，为Anthropic设定了周五的最后期限，并警告称，若不服从，惩罚将十分严厉。他表示，Anthropic可能会被列为“供应链风险”——这一designation通常用于被视为对手国家的企业。一旦被贴上该标签，国防部的供应商与承包商必须证明自己未使用Anthropic的模型。</p><p>阿莫迪表示，公司不会被吓倒。</p><p>他在周四的声明中写道：“这些威胁不会改变我们的立场：我们无法违背良知，答应他们的要求。”</p><p><strong>“得不偿失”</strong></p><p>这场不断升级的冲突，一直被其他AI实验室、行业专家与政府承包商密切关注。卡恩警告称，如果企业认定“得不偿失”，政府可能会将拥有优质产品的科技公司拒之门外。</p><p>卡恩说：“我真的、由衷地担心，私营企业会说‘今后与国防部门合作不值得’。而真正受影响的，是作战人员。”</p><p>OpenAI首席执行官萨姆・奥特曼周五接受CNBC采访时表示，他“个人认为，五角大楼不应以《国防生产法》威胁这些公司”。他认为，只要企业遵守法律保护条款，以及行业与Anthropic共同坚守的“少数红线”，企业自主选择与国防部合作就十分重要。</p><p>奥特曼在采访中说：“尽管我与Anthropic存在诸多分歧，但我大体上信任这家公司，也认为他们确实重视安全。我很高兴他们一直在支持我方作战人员。目前还不清楚此事会如何发展。”</p><p>近日，Anthropic及行业内其他公司的多名员工纷纷在社交媒体上表达对该公司的支持。</p><p>OpenAI技术人员乔希・麦格拉思周二在X平台发文称，对“正在发生的一切感到无言以对”。</p><p>据相关网站显示，谷歌与OpenAI的330多名员工也签署了一封题为《我们不会被分裂》的公开信，旨在“在国防部的压力下达成共识、团结一致”。</p><p>信中写道：“我们希望领导层能摒弃分歧，携手并肩，继续拒绝战争部当前的要求——即允许其使用我们的模型进行国内大规模监控，以及在无人类监督的情况下自主杀人。”</p><p><strong>相关背景</strong></p><p>对Anthropic而言，这只是与特朗普政府的最新冲突。</p><p>白宫AI与加密货币沙皇、风险投资家戴维・萨克斯此前曾指责Anthropic因监管立场而支持“觉醒AI”，还称其“基于制造恐慌，实施精密的监管俘获策略”——此前，Anthropic一名高管于2025年10月发表了题为《技术乐观主义与适度恐惧》的文章。</p><p>与奥特曼、苹果首席执行官库克、谷歌首席执行官桑达尔・皮查伊等其他行业高管不同，<strong>阿莫迪基本避免与特朗普总统接触。</strong>值得注意的是，他并未出席去年特朗普的就职典礼。</p><p>今年1月，赫格塞思发布了一份题为《加速美国军事AI主导地位》的备忘录。他在其中写道，国防部不得采用“<strong>融入意识形态‘调校’</strong>”的AI模型，还表示国防部“必须使用不受使用政策限制、不会限制合法军事应用的模型”。</p><p>尽管阿莫迪坚守公司对模型安全使用的承诺，但他周四表示，Anthropic“强烈希望”继续与国防部合作，支持美国国家安全。</p><p>阿莫迪写道：“若国防部选择终止与Anthropic的合作，我们将协助平稳过渡至其他供应商，避免对当前军事规划、行动及其他关键任务造成任何干扰。”</p></div>  
<hr>
<a href="https://m.cnbeta.com.tw/wap/view/1551570.htm",target="_blank" rel="noopener noreferrer">原文链接</a>
